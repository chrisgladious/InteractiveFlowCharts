{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d350c3",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Pajala ARV Flöden\n",
    "Data leverarad av Kristofer Grammer <kristofer.gramner@gefasystem.se>. Data bearbetat och diagram skapade av Christian Nilsson med hjälp av Github Copilot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fb41e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .\\.venv\\Scripts\\Activate.ps1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c7cf8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "def dprint(x): # https://stackoverflow.com/questions/32000934/print-a-variables-name-and-value/57225950#57225950\n",
    "    frame = inspect.currentframe().f_back\n",
    "    s = inspect.getframeinfo(frame).code_context[0]\n",
    "    r = re.search(r\"\\((.*)\\)\", s).group(1)\n",
    "    print(\"{} = {}\".format(r,x))\n",
    "\n",
    "def _pk1_path_for_file(file_path):\n",
    "    \"\"\"Return Path for .pk1 cache file stored next to the input file with same base name and extension '.pk1'.\"\"\"\n",
    "    p = Path(file_path) if not isinstance(file_path, Path) else file_path\n",
    "    return p.with_suffix('.pk1')\n",
    "\n",
    "def load_or_cache_excel(xlsx_path, read_kwargs=None, force_refresh=False):\n",
    "    \"\"\"Load DataFrame from a .pk1 cache next to the xlsx if present; otherwise read the xlsx and save the .pk1.\n",
    "    Returns the DataFrame.\n",
    "    read_kwargs: dict forwarded to pd.read_excel.\n",
    "    force_refresh: if True, re-read the Excel and overwrite cache.\"\"\"\n",
    "    read_kwargs = read_kwargs or {}\n",
    "    pk1 = _pk1_path_for_file(xlsx_path)\n",
    "    if pk1.exists() and not force_refresh:\n",
    "        try:\n",
    "            df = pd.read_pickle(pk1)\n",
    "            print(f'Loaded cache {pk1}')\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f'Warning: failed to load {pk1} (will re-read Excel): {e}')\n",
    "    # read Excel and attempt to save cache\n",
    "    df = pd.read_excel(xlsx_path, **read_kwargs)\n",
    "    try:\n",
    "        df.to_pickle(pk1)\n",
    "        print(f'Saved cache {pk1}')\n",
    "    except Exception as e:\n",
    "        print(f'Warning: could not save cache {pk1}: {e}')\n",
    "    return df\n",
    "\n",
    "def load_or_cache_csv(csv_path, read_kwargs=None, force_refresh=False):\n",
    "    \"\"\"Load DataFrame from a .pk1 cache next to the csv if present; otherwise read the csv and save the .pk1.\n",
    "    Returns the DataFrame.\n",
    "    read_kwargs: dict forwarded to pd.read_csv.\n",
    "    force_refresh: if True, re-read the CSV and overwrite cache.\"\"\"\n",
    "    read_kwargs = read_kwargs or {}\n",
    "    # Set default read parameters for our specific CSV format\n",
    "    default_params = {\n",
    "        'sep': ';',  # semicolon separated\n",
    "        'decimal': ',',  # comma as decimal separator\n",
    "        'parse_dates': ['TimeDate'],  # parse TimeDate column as datetime\n",
    "    }\n",
    "    # Update with any user-provided parameters\n",
    "    read_kwargs = {**default_params, **read_kwargs}\n",
    "    \n",
    "    pk1 = _pk1_path_for_file(csv_path)\n",
    "    if pk1.exists() and not force_refresh:\n",
    "        try:\n",
    "            df = pd.read_pickle(pk1)\n",
    "            print(f'Loaded cache {pk1}')\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f'Warning: failed to load {pk1} (will re-read CSV): {e}')\n",
    "    # read CSV and attempt to save cache\n",
    "    df = pd.read_csv(csv_path, **read_kwargs)\n",
    "    try:\n",
    "        df.to_pickle(pk1)\n",
    "        print(f'Saved cache {pk1}')\n",
    "    except Exception as e:\n",
    "        print(f'Warning: could not save cache {pk1}: {e}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40bfd7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache c:\\Users\\chrini\\OneDrive - Norconsult Group\\Projekt\\1097224_Pajala ARV\\4 Underlag\\Mejl\\20251104_1609_Re_ Malmberg Water i Yngsjö - ARV Pajala, åtgärd diverse styrpunkter_Kristofer Gramner\\20251104\\FT10101.pk1\n",
      "Loaded cache c:\\Users\\chrini\\OneDrive - Norconsult Group\\Projekt\\1097224_Pajala ARV\\4 Underlag\\Mejl\\20251104_1609_Re_ Malmberg Water i Yngsjö - ARV Pajala, åtgärd diverse styrpunkter_Kristofer Gramner\\20251104\\FT72101.pk1\n",
      "Loaded cache c:\\Users\\chrini\\OneDrive - Norconsult Group\\Projekt\\1097224_Pajala ARV\\4 Underlag\\Mejl\\20251104_1609_Re_ Malmberg Water i Yngsjö - ARV Pajala, åtgärd diverse styrpunkter_Kristofer Gramner\\20251104\\FT30101.pk1\n",
      "Loaded cache c:\\Users\\chrini\\OneDrive - Norconsult Group\\Projekt\\1097224_Pajala ARV\\4 Underlag\\Mejl\\20251104_1609_Re_ Malmberg Water i Yngsjö - ARV Pajala, åtgärd diverse styrpunkter_Kristofer Gramner\\20251104\\FT80101.pk1\n",
      "Loaded cache c:\\Users\\chrini\\OneDrive - Norconsult Group\\Projekt\\1097224_Pajala ARV\\4 Underlag\\Mejl\\20251104_1609_Re_ Malmberg Water i Yngsjö - ARV Pajala, åtgärd diverse styrpunkter_Kristofer Gramner\\20251104\\LT23101.pk1\n"
     ]
    }
   ],
   "source": [
    "# Read CSV files (with pk1 cache next to each csv). Uses load_or_cache_csv from previous cell.\n",
    "csv_file_path_FT10101 = r'c:\\Users\\chrini\\OneDrive - Norconsult Group\\Projekt\\1097224_Pajala ARV\\4 Underlag\\Mejl\\20251104_1609_Re_ Malmberg Water i Yngsjö - ARV Pajala, åtgärd diverse styrpunkter_Kristofer Gramner\\20251104\\FT10101.csv'\n",
    "csv_file_path_FT30101 = r'c:\\Users\\chrini\\OneDrive - Norconsult Group\\Projekt\\1097224_Pajala ARV\\4 Underlag\\Mejl\\20251104_1609_Re_ Malmberg Water i Yngsjö - ARV Pajala, åtgärd diverse styrpunkter_Kristofer Gramner\\20251104\\FT30101.csv'\n",
    "csv_file_path_FT72101 = r'c:\\Users\\chrini\\OneDrive - Norconsult Group\\Projekt\\1097224_Pajala ARV\\4 Underlag\\Mejl\\20251104_1609_Re_ Malmberg Water i Yngsjö - ARV Pajala, åtgärd diverse styrpunkter_Kristofer Gramner\\20251104\\FT72101.csv'\n",
    "csv_file_path_FT80101 = r'c:\\Users\\chrini\\OneDrive - Norconsult Group\\Projekt\\1097224_Pajala ARV\\4 Underlag\\Mejl\\20251104_1609_Re_ Malmberg Water i Yngsjö - ARV Pajala, åtgärd diverse styrpunkter_Kristofer Gramner\\20251104\\FT80101.csv'\n",
    "csv_file_path_LT23101 = r'c:\\Users\\chrini\\OneDrive - Norconsult Group\\Projekt\\1097224_Pajala ARV\\4 Underlag\\Mejl\\20251104_1609_Re_ Malmberg Water i Yngsjö - ARV Pajala, åtgärd diverse styrpunkter_Kristofer Gramner\\20251104\\LT23101.csv'\n",
    "\n",
    "# Load using the helper which places the .pk1 next to the csv with same base name\n",
    "df_Inflöde_FT10101 = load_or_cache_csv(csv_file_path_FT10101) #Inflöde\n",
    "df_Utflöde_FT72101 = load_or_cache_csv(csv_file_path_FT72101) #Utflöde\n",
    "df_MBBRflöde_FT30101 = load_or_cache_csv(csv_file_path_FT30101) #MBBR-flöde\n",
    "df_Inflöde_Extenslam_FT80101 = load_or_cache_csv(csv_file_path_FT80101) #Inflöde Extenslam\n",
    "df_Nivå_Bräddning_LT23101 = load_or_cache_csv(csv_file_path_LT23101) #Utflöde Bräddning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "856a7cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_Utflöde_FT72101.head() =                      Utflöde FT-72101\n",
      "DateTime                             \n",
      "2024-11-01 03:01:00         71.990110\n",
      "2024-11-01 03:02:00         37.916668\n",
      "2024-11-01 03:03:00         17.846454\n",
      "2024-11-01 03:04:00         11.633287\n",
      "2024-11-01 03:05:00         45.686008\n",
      "df_Inflöde_Extenslam_FT80101.head() =                      Inflöde Extenslam FT80101\n",
      "DateTime                                      \n",
      "2024-11-01 03:01:00                  -0.486475\n",
      "2024-11-01 03:02:00                  -0.486475\n",
      "2024-11-01 03:03:00                  -0.486475\n",
      "2024-11-01 03:04:00                  -0.486475\n",
      "2024-11-01 03:05:00                  -0.486475\n",
      "df_Nivå_Bräddning_LT23101.head() =                      Nivå Bräddning LT23101\n",
      "DateTime                                   \n",
      "2024-11-01 03:01:00                0.148113\n",
      "2024-11-01 03:02:00                0.148113\n",
      "2024-11-01 03:03:00                0.148113\n",
      "2024-11-01 03:04:00                0.148113\n",
      "2024-11-01 03:05:00                0.148113\n",
      "\n",
      "Merged DataFrame:\n",
      "df_ax.head() =                      Inflöde FT-10101  Utflöde FT-72101  \\\n",
      "DateTime                                                  \n",
      "2024-11-01 03:01:00         48.163444         71.990110   \n",
      "2024-11-01 03:02:00         53.358573         37.916668   \n",
      "2024-11-01 03:03:00         48.372349         17.846454   \n",
      "2024-11-01 03:04:00         44.189613         11.633287   \n",
      "2024-11-01 03:05:00         24.777310         45.686008   \n",
      "\n",
      "                     Inflöde Extenslam FT80101  \n",
      "DateTime                                        \n",
      "2024-11-01 03:01:00                        0.0  \n",
      "2024-11-01 03:02:00                        0.0  \n",
      "2024-11-01 03:03:00                        0.0  \n",
      "2024-11-01 03:04:00                        0.0  \n",
      "2024-11-01 03:05:00                        0.0  \n",
      "\n",
      "Missing values in merged DataFrame:\n",
      "df_ax.isna().sum() = Inflöde FT-10101             7\n",
      "Utflöde FT-72101             1\n",
      "Inflöde Extenslam FT80101    0\n",
      "dtype: int64\n",
      "\n",
      "Merged DataFrame:\n",
      "df_ax.head() =                      Inflöde FT-10101  Utflöde FT-72101  \\\n",
      "DateTime                                                  \n",
      "2024-11-01 03:01:00         48.163444         71.990110   \n",
      "2024-11-01 03:02:00         53.358573         37.916668   \n",
      "2024-11-01 03:03:00         48.372349         17.846454   \n",
      "2024-11-01 03:04:00         44.189613         11.633287   \n",
      "2024-11-01 03:05:00         24.777310         45.686008   \n",
      "\n",
      "                     Inflöde Extenslam FT80101  \n",
      "DateTime                                        \n",
      "2024-11-01 03:01:00                        0.0  \n",
      "2024-11-01 03:02:00                        0.0  \n",
      "2024-11-01 03:03:00                        0.0  \n",
      "2024-11-01 03:04:00                        0.0  \n",
      "2024-11-01 03:05:00                        0.0  \n",
      "\n",
      "Missing values in merged DataFrame:\n",
      "df_ax.isna().sum() = Inflöde FT-10101             7\n",
      "Utflöde FT-72101             1\n",
      "Inflöde Extenslam FT80101    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# dprint(df_1.head())\n",
    "df_Inflöde_FT10101.rename(columns={'TimeDate': 'DateTime', 'Val':'Inflöde FT-10101'}, inplace=True)\n",
    "df_Inflöde_FT10101['DateTime'] = pd.to_datetime(df_Inflöde_FT10101['DateTime'])\n",
    "df_Inflöde_FT10101.drop(columns=['ID', 'TimeLength'], inplace=True)\n",
    "df_Inflöde_FT10101.set_index('DateTime', inplace=True)\n",
    "# dprint(df_1.head())\n",
    "\n",
    "\n",
    "# print(df_2.head())\n",
    "df_Utflöde_FT72101.rename(columns={'TimeDate': 'DateTime', 'Val':'Utflöde FT-72101'}, inplace=True)\n",
    "df_Utflöde_FT72101['DateTime'] = pd.to_datetime(df_Utflöde_FT72101['DateTime'])\n",
    "df_Utflöde_FT72101.drop(columns=['ID', 'TimeLength'], inplace=True)\n",
    "df_Utflöde_FT72101.set_index('DateTime', inplace=True)\n",
    "dprint(df_Utflöde_FT72101.head())\n",
    "\n",
    "df_Inflöde_Extenslam_FT80101.rename(columns={'TimeDate': 'DateTime', 'Val':'Inflöde Extenslam FT80101'}, inplace=True)\n",
    "df_Inflöde_Extenslam_FT80101['DateTime'] = pd.to_datetime(df_Inflöde_Extenslam_FT80101['DateTime'])\n",
    "df_Inflöde_Extenslam_FT80101.drop(columns=['ID', 'TimeLength'], inplace=True)\n",
    "df_Inflöde_Extenslam_FT80101.set_index('DateTime', inplace=True)\n",
    "dprint(df_Inflöde_Extenslam_FT80101.head())\n",
    "df_Inflöde_Extenslam_FT80101_before_zeroflow_calib = df_Inflöde_Extenslam_FT80101\n",
    "df_Inflöde_Extenslam_FT80101['Inflöde Extenslam FT80101'] = df_Inflöde_Extenslam_FT80101['Inflöde Extenslam FT80101'] + 0.486474692821503\n",
    "\n",
    "df_Nivå_Bräddning_LT23101.rename(columns={'TimeDate': 'DateTime', 'Val':'Nivå Bräddning LT23101'}, inplace=True)\n",
    "df_Nivå_Bräddning_LT23101['DateTime'] = pd.to_datetime(df_Nivå_Bräddning_LT23101['DateTime'])\n",
    "df_Nivå_Bräddning_LT23101.drop(columns=['ID', 'TimeLength'], inplace=True)\n",
    "df_Nivå_Bräddning_LT23101.set_index('DateTime', inplace=True)\n",
    "dprint(df_Nivå_Bräddning_LT23101.head())\n",
    "\n",
    "# Merge the DataFrames on the DateTime index, aligning values\n",
    "# Using merge instead of concat to handle any duplicate indices\n",
    "# Merge all DataFrames sequentially\n",
    "df_ax = pd.merge(df_Inflöde_FT10101, df_Utflöde_FT72101, left_index=True, right_index=True, how='outer')\n",
    "df_ax = pd.merge(df_ax, df_Inflöde_Extenslam_FT80101, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "# Show the result\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "dprint(df_ax.head())\n",
    "\n",
    "# Check for any missing values after merge\n",
    "print(\"\\nMissing values in merged DataFrame:\")\n",
    "dprint(df_ax.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f17e3f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df_Inflöde_FT10101: ['Inflöde FT-10101']\n",
      "Columns in df_Utflöde_FT72101: ['Utflöde FT-72101']\n",
      "Columns in df_ax: ['Inflöde FT-10101', 'Utflöde FT-72101', 'Inflöde Extenslam FT80101']\n"
     ]
    }
   ],
   "source": [
    "# Show all column names to verify what needs renaming\n",
    "print(\"Columns in df_Inflöde_FT10101:\", df_Inflöde_FT10101.columns.tolist())\n",
    "print(\"Columns in df_Utflöde_FT72101:\", df_Utflöde_FT72101.columns.tolist())\n",
    "print(\"Columns in df_ax:\", df_ax.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09c70e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DateTime indices with missing FT-10101:\n",
      "['2025-11-04 15:44:00', '2025-11-04 15:45:00', '2025-11-04 15:46:00', '2025-11-04 15:47:00', '2025-11-04 15:48:00', '2025-11-04 15:49:00', '2025-11-04 15:50:00']\n",
      "\n",
      "DateTime indices with missing FT-72101:\n",
      "['2025-11-04 15:50:00']\n",
      "\n",
      "Summary of gaps:\n",
      "Total rows in merged DataFrame: 513884\n",
      "Rows with missing FT-10101: 7\n",
      "Rows with missing FT-72101: 1\n",
      "Rows with data in both columns: 513877\n"
     ]
    }
   ],
   "source": [
    "# Show DateTime indices where there are missing values\n",
    "print(\"\\nDateTime indices with missing FT-10101:\")\n",
    "print(df_ax[df_ax['Inflöde FT-10101'].isna()].index.strftime('%Y-%m-%d %H:%M:%S').tolist())\n",
    "\n",
    "print(\"\\nDateTime indices with missing FT-72101:\")\n",
    "print(df_ax[df_ax['Utflöde FT-72101'].isna()].index.strftime('%Y-%m-%d %H:%M:%S').tolist())\n",
    "\n",
    "# Print summary of gaps\n",
    "print(\"\\nSummary of gaps:\")\n",
    "print(f\"Total rows in merged DataFrame: {len(df_ax)}\")\n",
    "print(f\"Rows with missing FT-10101: {df_ax['Inflöde FT-10101'].isna().sum()}\")\n",
    "print(f\"Rows with missing FT-72101: {df_ax['Utflöde FT-72101'].isna().sum()}\")\n",
    "print(f\"Rows with data in both columns: {len(df_ax) - df_ax.isna().any(axis=1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133f22f",
   "metadata": {},
   "source": [
    "# Check and Remove Duplicate Timestamps\n",
    "Before calculating moving averages, we need to identify and remove any duplicate timestamps from the source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a4a0f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: df_ax has 7 duplicate indices. Keeping first occurrence.\n",
      "Warning: df_Inflöde_Extenslam_FT80101 has 1 duplicate indices. Keeping first occurrence.\n",
      "Warning: df_Nivå_Bräddning_LT23101 has 1 duplicate indices. Keeping first occurrence.\n",
      "\n",
      "Total duplicate rows collected: 12\n",
      "Unique duplicate timestamps: 1\n",
      "Duplicate timestamps saved to: duplicate_timestamps.csv\n",
      "\n",
      "Cleaned DataFrame sizes:\n",
      "  df_ax: 513877 rows\n",
      "  df_Inflöde_Extenslam_FT80101: 513877 rows\n",
      "  df_Nivå_Bräddning_LT23101: 513892 rows\n",
      "\n",
      "Total duplicate rows collected: 12\n",
      "Unique duplicate timestamps: 1\n",
      "Duplicate timestamps saved to: duplicate_timestamps.csv\n",
      "\n",
      "Cleaned DataFrame sizes:\n",
      "  df_ax: 513877 rows\n",
      "  df_Inflöde_Extenslam_FT80101: 513877 rows\n",
      "  df_Nivå_Bräddning_LT23101: 513892 rows\n"
     ]
    }
   ],
   "source": [
    "# Collect all duplicate timestamps before removing them\n",
    "df_duplicate_timestamps = pd.DataFrame()\n",
    "\n",
    "# Helper function to collect duplicates from a DataFrame\n",
    "def collect_duplicates(df, df_name):\n",
    "    \"\"\"Collect duplicate rows and return them with a source column.\"\"\"\n",
    "    if df.index.duplicated().any():\n",
    "        dup_mask = df.index.duplicated(keep=False)  # Mark ALL duplicates, not just subsequent ones\n",
    "        dup_rows = df[dup_mask].copy()\n",
    "        dup_rows['Source'] = df_name\n",
    "        dup_rows['DuplicateGroup'] = dup_rows.index.astype(str)\n",
    "        return dup_rows\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Check for and collect duplicate indices before removal\n",
    "frames_to_check = {\n",
    "    'df_ax': df_ax,\n",
    "    'df_Inflöde_Extenslam_FT80101': df_Inflöde_Extenslam_FT80101,\n",
    "    'df_Nivå_Bräddning_LT23101': df_Nivå_Bräddning_LT23101\n",
    "}\n",
    "\n",
    "duplicate_collections = []\n",
    "for name, df_frame in frames_to_check.items():\n",
    "    if df_frame.index.duplicated().any():\n",
    "        dup_count = df_frame.index.duplicated().sum()\n",
    "        print(f\"Warning: {name} has {dup_count} duplicate indices. Keeping first occurrence.\")\n",
    "        \n",
    "        # Collect duplicates\n",
    "        dup_df = collect_duplicates(df_frame, name)\n",
    "        if not dup_df.empty:\n",
    "            duplicate_collections.append(dup_df)\n",
    "        \n",
    "        # Remove duplicates from the original frame\n",
    "        if name == 'df_ax':\n",
    "            df_ax = df_ax[~df_ax.index.duplicated(keep='first')]\n",
    "        elif name == 'df_Inflöde_Extenslam_FT80101':\n",
    "            df_Inflöde_Extenslam_FT80101 = df_Inflöde_Extenslam_FT80101[~df_Inflöde_Extenslam_FT80101.index.duplicated(keep='first')]\n",
    "        elif name == 'df_Nivå_Bräddning_LT23101':\n",
    "            df_Nivå_Bräddning_LT23101 = df_Nivå_Bräddning_LT23101[~df_Nivå_Bräddning_LT23101.index.duplicated(keep='first')]\n",
    "\n",
    "# Combine all duplicate collections into one DataFrame\n",
    "if duplicate_collections:\n",
    "    df_duplicate_timestamps = pd.concat(duplicate_collections, axis=0)\n",
    "    df_duplicate_timestamps = df_duplicate_timestamps.sort_values(['DuplicateGroup', 'Source'])\n",
    "    print(f\"\\nTotal duplicate rows collected: {len(df_duplicate_timestamps)}\")\n",
    "    print(f\"Unique duplicate timestamps: {df_duplicate_timestamps.index.nunique()}\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_path = 'duplicate_timestamps.csv'\n",
    "    df_duplicate_timestamps.to_csv(csv_path)\n",
    "    print(f\"Duplicate timestamps saved to: {csv_path}\")\n",
    "else:\n",
    "    print(\"\\nNo duplicates found in any DataFrame.\")\n",
    "\n",
    "print(f\"\\nCleaned DataFrame sizes:\")\n",
    "print(f\"  df_ax: {len(df_ax)} rows\")\n",
    "print(f\"  df_Inflöde_Extenslam_FT80101: {len(df_Inflöde_Extenslam_FT80101)} rows\")\n",
    "print(f\"  df_Nivå_Bräddning_LT23101: {len(df_Nivå_Bräddning_LT23101)} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3605581",
   "metadata": {},
   "source": [
    "# Calculate Velocity for FT-10101\n",
    "Convert flow rate (m³/s) to velocity (m/s) using pipe inside diameter of 300 mm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caf1a416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe inside diameter: 300.0 mm\n",
      "Cross-sectional area: 0.070686 m²\n",
      "\n",
      "Velocity statistics:\n",
      "count    5.138700e+05\n",
      "mean     1.385685e-01\n",
      "std      5.307203e-02\n",
      "min     -6.012520e-08\n",
      "25%      1.078246e-01\n",
      "50%      1.340951e-01\n",
      "75%      1.617729e-01\n",
      "max      7.404189e-01\n",
      "Name: Inflöde FT-10101 [m/s], dtype: float64\n",
      "\n",
      "First few values:\n",
      "                     Inflöde FT-10101 [m/s]\n",
      "DateTime                                   \n",
      "2024-11-01 03:01:00                0.189270\n",
      "2024-11-01 03:02:00                0.209686\n",
      "2024-11-01 03:03:00                0.190091\n",
      "2024-11-01 03:04:00                0.173654\n",
      "2024-11-01 03:05:00                0.097369\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Pipe inside diameter in meters\n",
    "diameter_m = 0.300  # 300 mm = 0.3 m\n",
    "\n",
    "# Calculate cross-sectional area: A = π × (d/2)²\n",
    "area_m2 = np.pi * (diameter_m / 2) ** 2\n",
    "\n",
    "print(f\"Pipe inside diameter: {diameter_m * 1000} mm\")\n",
    "print(f\"Cross-sectional area: {area_m2:.6f} m²\")\n",
    "\n",
    "# Calculate velocity: v = Q / A\n",
    "# df_ax['Inflöde FT-10101'] is in m³/s (assuming flow rate units)\n",
    "# Velocity will be in m/s\n",
    "df_Inflöde_FT10101_mps = pd.DataFrame(index=df_ax.index)\n",
    "df_Inflöde_FT10101_mps['Inflöde FT-10101 [m/s]'] = df_ax['Inflöde FT-10101'] / 3.6 / 1000 / area_m2\n",
    "\n",
    "print(f\"\\nVelocity statistics:\")\n",
    "print(df_Inflöde_FT10101_mps['Inflöde FT-10101 [m/s]'].describe())\n",
    "print(f\"\\nFirst few values:\")\n",
    "print(df_Inflöde_FT10101_mps.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5b8cf3",
   "metadata": {},
   "source": [
    "# Calculate Moving Averages for Velocity\n",
    "Apply the same time-based moving average windows (1h, 24h, 7d) to the velocity data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7319c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Velocity DataFrame with Moving Averages:\n",
      "Shape: (513877, 4)\n",
      "Columns: ['Inflöde FT-10101 [m/s]', 'Inflöde FT-10101 [m/s]_MA_1h', 'Inflöde FT-10101 [m/s]_MA_24h', 'Inflöde FT-10101 [m/s]_MA_7d']\n",
      "\n",
      "First few rows:\n",
      "                     Inflöde FT-10101 [m/s]  Inflöde FT-10101 [m/s]_MA_1h  \\\n",
      "DateTime                                                                    \n",
      "2024-11-01 03:01:00                0.189270                      0.189270   \n",
      "2024-11-01 03:02:00                0.209686                      0.199478   \n",
      "2024-11-01 03:03:00                0.190091                      0.196349   \n",
      "2024-11-01 03:04:00                0.173654                      0.190675   \n",
      "2024-11-01 03:05:00                0.097369                      0.172014   \n",
      "\n",
      "                     Inflöde FT-10101 [m/s]_MA_24h  \\\n",
      "DateTime                                             \n",
      "2024-11-01 03:01:00                       0.189270   \n",
      "2024-11-01 03:02:00                       0.199478   \n",
      "2024-11-01 03:03:00                       0.196349   \n",
      "2024-11-01 03:04:00                       0.190675   \n",
      "2024-11-01 03:05:00                       0.172014   \n",
      "\n",
      "                     Inflöde FT-10101 [m/s]_MA_7d  \n",
      "DateTime                                           \n",
      "2024-11-01 03:01:00                      0.189270  \n",
      "2024-11-01 03:02:00                      0.199478  \n",
      "2024-11-01 03:03:00                      0.196349  \n",
      "2024-11-01 03:04:00                      0.190675  \n",
      "2024-11-01 03:05:00                      0.172014  \n"
     ]
    }
   ],
   "source": [
    "# Calculate moving averages for velocity data\n",
    "# Prepare container for velocity moving averages\n",
    "df_velocity_ma = pd.DataFrame(index=df_Inflöde_FT10101_mps.index)\n",
    "\n",
    "# Define the same time-based windows as used for flows\n",
    "windows_velocity = { '1h': '60min', '24h': '24h', '7d': '7D' }\n",
    "\n",
    "for col in df_Inflöde_FT10101_mps.columns:\n",
    "    for w_label, w_offset in windows_velocity.items():\n",
    "        # Use time-based rolling which is robust to missing/irregular timestamps\n",
    "        ma = df_Inflöde_FT10101_mps[col].rolling(w_offset, min_periods=1).mean()\n",
    "        ma_col_name = f\"{col}_MA_{w_label}\"\n",
    "        df_velocity_ma[ma_col_name] = ma\n",
    "\n",
    "# Concat original velocity data with its moving averages\n",
    "df_velocity_with_ma = pd.concat([df_Inflöde_FT10101_mps, df_velocity_ma], axis=1)\n",
    "\n",
    "print(\"Velocity DataFrame with Moving Averages:\")\n",
    "print(f\"Shape: {df_velocity_with_ma.shape}\")\n",
    "print(f\"Columns: {df_velocity_with_ma.columns.tolist()}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_velocity_with_ma.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "492786de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed df_Utflöde_Bräddning_LT23101:\n",
      "df_Utflöde_Bräddning_LT23101.head() =                      Utflöde Bräddning LT23101\n",
      "DateTime                                      \n",
      "2024-11-01 03:01:00                        0.0\n",
      "2024-11-01 03:02:00                        0.0\n",
      "2024-11-01 03:03:00                        0.0\n",
      "2024-11-01 03:04:00                        0.0\n",
      "2024-11-01 03:05:00                        0.0\n",
      "df_Utflöde_Bräddning_LT23101: 513892 rows\n"
     ]
    }
   ],
   "source": [
    "# Compute overflow rate from level df_Nivå_Bräddning_LT23101 -> df_Utflöde_Bräddning_LT23101\n",
    "import numpy as np\n",
    "\n",
    "# Constants for the V-notch weir formula (Excel equivalent):\n",
    "# =IF(E2<0.25;0;0.58*8/15*TAN(RADIANS(100)/2) * (E2-H)^(2.5) * SQRT(2*g) * 3600)\n",
    "H_threshold = 0.25  # m, crest level H in the formula\n",
    "angle_deg = 100.0   # degrees for the V-notch angle\n",
    "g = 9.81            # m/s^2\n",
    "\n",
    "# Prepare head above crest (clipped at 0)\n",
    "level_col = 'Nivå Bräddning LT23101'\n",
    "head = (df_Nivå_Bräddning_LT23101[level_col] - H_threshold).clip(lower=0.0)\n",
    "\n",
    "# Precompute constant multiplier K = 0.58*8/15*TAN(RADIANS(100)/2)*SQRT(2*g)*3600\n",
    "K = 0.58 * (8.0/15.0) * np.tan(np.radians(angle_deg)/2.0) * np.sqrt(2.0 * g) * 3600.0\n",
    "\n",
    "# Flow [m3/h]\n",
    "flow_m3h = K * np.power(head, 2.5)\n",
    "\n",
    "# Build resulting DataFrame\n",
    "df_Utflöde_Bräddning_LT23101 = pd.DataFrame(\n",
    "    data={'Utflöde Bräddning LT23101': flow_m3h},\n",
    "    index=df_Nivå_Bräddning_LT23101.index\n",
    ")\n",
    "\n",
    "# Check for and remove duplicates in the overflow DataFrame\n",
    "if df_Utflöde_Bräddning_LT23101.index.duplicated().any():\n",
    "    dup_count = df_Utflöde_Bräddning_LT23101.index.duplicated().sum()\n",
    "    print(f\"Warning: df_Utflöde_Bräddning_LT23101 has {dup_count} duplicate indices. Keeping first occurrence.\")\n",
    "    df_Utflöde_Bräddning_LT23101 = df_Utflöde_Bräddning_LT23101[~df_Utflöde_Bräddning_LT23101.index.duplicated(keep='first')]\n",
    "\n",
    "# Optional diagnostics\n",
    "print('Computed df_Utflöde_Bräddning_LT23101:')\n",
    "dprint(df_Utflöde_Bräddning_LT23101.head())\n",
    "print(f'df_Utflöde_Bräddning_LT23101: {len(df_Utflöde_Bräddning_LT23101)} rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e71a7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a9a47df",
   "metadata": {},
   "source": [
    "# Calculate Moving Averages and Flow Plant Balance\n",
    "Now that duplicates have been removed, we can safely calculate moving averages with different window sizes to smooth the time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29672c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned lengths (L, R): 513892 513892\n",
      "Left NaNs total: 53\n",
      "Right NaNs total: 0\n",
      "len(df_flows.columns) = 16\n",
      "len(df_flowdiff.columns) = 3\n"
     ]
    }
   ],
   "source": [
    "# Calculate moving averages for each column (time-based windows)\n",
    "# Each row in df_ax represents 1 minute, so use time-based rolling windows\n",
    "import pandas as pd\n",
    "\n",
    "# First, merge overflow flow into df_ax so MAs can be calculated for it\n",
    "df_ax = pd.merge(df_ax, df_Utflöde_Bräddning_LT23101, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "# Prepare container for moving averages\n",
    "df_ma = pd.DataFrame(index=df_ax.index)\n",
    "\n",
    "# Define time-based windows (labels -> pandas offset strings)\n",
    "windows = { '1h': '60min', '24h': '24h', '7d': '7D' }\n",
    "\n",
    "for col in df_ax.columns:\n",
    "    for w_label, w_offset in windows.items():\n",
    "        # Use time-based rolling which is robust to missing/irregular timestamps\n",
    "        ma = df_ax[col].rolling(w_offset, min_periods=1).mean()\n",
    "        ma_col_name = f\"{col}_MA_{w_label}\"\n",
    "        df_ma[ma_col_name] = ma\n",
    "\n",
    "# Compute differences (Inflöde - Utflöde - Bräddning) for each moving-average window in a separate DataFrame\n",
    "# Source column names in df_ax are 'Inflöde FT-10101', 'Utflöde FT-72101', and 'Utflöde Bräddning LT23101'\n",
    "df_ma_diff = pd.DataFrame(index=df_ax.index)\n",
    "inflow_main = 'Inflöde FT-10101'\n",
    "outflow_main = 'Utflöde FT-72101'\n",
    "inflow_externslam = 'Inflöde Extenslam FT80101'\n",
    "outflow_bräddning = 'Utflöde Bräddning LT23101'\n",
    "\n",
    "for w_label in windows.keys():\n",
    "    col_inflow_main = f\"{inflow_main}_MA_{w_label}\"\n",
    "    col_outflow_main = f\"{outflow_main}_MA_{w_label}\"\n",
    "    col_outflow_externslam = f\"{inflow_externslam}_MA_{w_label}\"\n",
    "    col_outflow_bräddning = f\"{outflow_bräddning}_MA_{w_label}\"\n",
    "    diff_col = f\"Diff_MA_{w_label}\"\n",
    "    if col_inflow_main in df_ma.columns and col_outflow_main in df_ma.columns and col_outflow_bräddning in df_ma.columns:\n",
    "        df_ma_diff[diff_col] = (df_ma[col_inflow_main] + df_ma[col_outflow_externslam] - df_ma[col_outflow_main] - df_ma[col_outflow_bräddning])/(df_ma[col_inflow_main] + df_ma[col_outflow_externslam])\n",
    "    else:\n",
    "        # If one of the MA columns is missing, create the diff column with NaNs and warn\n",
    "        df_ma_diff[diff_col] = pd.NA\n",
    "        print(f\"Warning: cannot compute {diff_col} because one or more required columns are missing\")\n",
    "\n",
    "# Concat all data side-by-side for left axis (includes original values and their moving averages)\n",
    "df_flows = pd.concat([df_ax, df_ma], axis=1)\n",
    "\n",
    "# Concat all data side-by-side for right axis (only flow differences)\n",
    "df_flowdiff = df_ma_diff\n",
    "\n",
    "# Align left and right frames to a common union index (sorted)\n",
    "union_idx = df_flows.index.union(df_flowdiff.index)\n",
    "try:\n",
    "    union_idx = union_idx.unique()\n",
    "except Exception:\n",
    "    pass\n",
    "union_idx = union_idx.sort_values()\n",
    "\n",
    "df_flows = df_flows.reindex(union_idx)\n",
    "df_flowdiff = df_flowdiff.reindex(union_idx)\n",
    "\n",
    "# Optional: sanity prints\n",
    "print(\"Aligned lengths (L, R):\", len(df_flows.index), len(df_flowdiff.index))\n",
    "print(\"Left NaNs total:\", int(df_flows.isna().sum().sum()))\n",
    "print(\"Right NaNs total:\", int(df_flowdiff.isna().sum().sum()))\n",
    "\n",
    "# Debug: number of columns\n",
    "dprint(len(df_flows.columns))\n",
    "dprint(len(df_flowdiff.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "605ed4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate timestamps DataFrame shape: (12, 6)\n",
      "\n",
      "First few duplicate rows:\n",
      "                     Inflöde FT-10101  Utflöde FT-72101  \\\n",
      "DateTime                                                  \n",
      "2025-07-07 07:47:00               NaN               NaN   \n",
      "2025-07-07 07:47:00               NaN               NaN   \n",
      "2025-07-07 07:47:00               NaN               NaN   \n",
      "2025-07-07 07:47:00               NaN               NaN   \n",
      "2025-07-07 07:47:00         94.965556         38.107736   \n",
      "2025-07-07 07:47:00         94.965556         38.107736   \n",
      "2025-07-07 07:47:00         94.965556         38.107736   \n",
      "2025-07-07 07:47:00         94.965556         38.107736   \n",
      "2025-07-07 07:47:00         94.965556         38.107736   \n",
      "2025-07-07 07:47:00         94.965556         38.107736   \n",
      "2025-07-07 07:47:00         94.965556         38.107736   \n",
      "2025-07-07 07:47:00         94.965556         38.107736   \n",
      "\n",
      "                     Inflöde Extenslam FT80101                        Source  \\\n",
      "DateTime                                                                       \n",
      "2025-07-07 07:47:00                        0.0  df_Inflöde_Extenslam_FT80101   \n",
      "2025-07-07 07:47:00                        0.0  df_Inflöde_Extenslam_FT80101   \n",
      "2025-07-07 07:47:00                        NaN     df_Nivå_Bräddning_LT23101   \n",
      "2025-07-07 07:47:00                        NaN     df_Nivå_Bräddning_LT23101   \n",
      "2025-07-07 07:47:00                        0.0                         df_ax   \n",
      "2025-07-07 07:47:00                        0.0                         df_ax   \n",
      "2025-07-07 07:47:00                        0.0                         df_ax   \n",
      "2025-07-07 07:47:00                        0.0                         df_ax   \n",
      "2025-07-07 07:47:00                        0.0                         df_ax   \n",
      "2025-07-07 07:47:00                        0.0                         df_ax   \n",
      "2025-07-07 07:47:00                        0.0                         df_ax   \n",
      "2025-07-07 07:47:00                        0.0                         df_ax   \n",
      "\n",
      "                          DuplicateGroup  Nivå Bräddning LT23101  \n",
      "DateTime                                                          \n",
      "2025-07-07 07:47:00  2025-07-07 07:47:00                     NaN  \n",
      "2025-07-07 07:47:00  2025-07-07 07:47:00                     NaN  \n",
      "2025-07-07 07:47:00  2025-07-07 07:47:00                0.151694  \n",
      "2025-07-07 07:47:00  2025-07-07 07:47:00                0.151694  \n",
      "2025-07-07 07:47:00  2025-07-07 07:47:00                     NaN  \n",
      "2025-07-07 07:47:00  2025-07-07 07:47:00                     NaN  \n",
      "2025-07-07 07:47:00  2025-07-07 07:47:00                     NaN  \n",
      "2025-07-07 07:47:00  2025-07-07 07:47:00                     NaN  \n",
      "2025-07-07 07:47:00  2025-07-07 07:47:00                     NaN  \n",
      "2025-07-07 07:47:00  2025-07-07 07:47:00                     NaN  \n",
      "2025-07-07 07:47:00  2025-07-07 07:47:00                     NaN  \n",
      "2025-07-07 07:47:00  2025-07-07 07:47:00                     NaN  \n",
      "\n",
      "Duplicates by source:\n",
      "Source\n",
      "df_Inflöde_Extenslam_FT80101    2\n",
      "df_Nivå_Bräddning_LT23101       2\n",
      "df_ax                           8\n",
      "dtype: int64\n",
      "\n",
      "Unique duplicate timestamps:\n",
      "['2025-07-07 07:47:00']\n"
     ]
    }
   ],
   "source": [
    "# Display duplicate timestamps if any were found\n",
    "if 'df_duplicate_timestamps' in locals() and not df_duplicate_timestamps.empty:\n",
    "    print(f\"Duplicate timestamps DataFrame shape: {df_duplicate_timestamps.shape}\")\n",
    "    print(\"\\nFirst few duplicate rows:\")\n",
    "    print(df_duplicate_timestamps.head(20))\n",
    "    \n",
    "    # Show summary by source\n",
    "    print(\"\\nDuplicates by source:\")\n",
    "    print(df_duplicate_timestamps.groupby('Source').size())\n",
    "    \n",
    "    # Show the actual duplicate timestamps\n",
    "    print(\"\\nUnique duplicate timestamps:\")\n",
    "    print(sorted(df_duplicate_timestamps.index.unique().strftime('%Y-%m-%d %H:%M:%S').tolist()))\n",
    "else:\n",
    "    print(\"No duplicates were found or df_duplicate_timestamps is empty.\")\n",
    "    print(\"\\nNote: If you previously had duplicates, you may need to:\")\n",
    "    print(\"1. Re-run the data loading cells (cells 4-5)\")\n",
    "    print(\"2. Then re-run the moving averages cell to capture duplicates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b9be0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DUPLICATE TIMESTAMPS SUMMARY\n",
      "============================================================\n",
      "Total duplicate rows captured: 12\n",
      "Number of unique duplicate timestamps: 1\n",
      "\n",
      "Duplicates by source DataFrame:\n",
      "  df_Inflöde_Extenslam_FT80101: 2 rows\n",
      "  df_Nivå_Bräddning_LT23101: 2 rows\n",
      "  df_ax: 8 rows\n",
      "\n",
      "Unique timestamps that appear multiple times:\n",
      "  2025-07-07 07:47:00\n",
      "\n",
      "Example: Data for first duplicate timestamp\n",
      "                     Inflöde FT-10101  Utflöde FT-72101  Inflöde Extenslam FT80101                        Source       DuplicateGroup  Nivå Bräddning LT23101\n",
      "DateTime                                                                                                                                                     \n",
      "2025-07-07 07:47:00               NaN               NaN                        0.0  df_Inflöde_Extenslam_FT80101  2025-07-07 07:47:00                     NaN\n",
      "2025-07-07 07:47:00               NaN               NaN                        0.0  df_Inflöde_Extenslam_FT80101  2025-07-07 07:47:00                     NaN\n",
      "2025-07-07 07:47:00               NaN               NaN                        NaN     df_Nivå_Bräddning_LT23101  2025-07-07 07:47:00                0.151694\n",
      "2025-07-07 07:47:00               NaN               NaN                        NaN     df_Nivå_Bräddning_LT23101  2025-07-07 07:47:00                0.151694\n",
      "2025-07-07 07:47:00         94.965556         38.107736                        0.0                         df_ax  2025-07-07 07:47:00                     NaN\n",
      "2025-07-07 07:47:00         94.965556         38.107736                        0.0                         df_ax  2025-07-07 07:47:00                     NaN\n",
      "2025-07-07 07:47:00         94.965556         38.107736                        0.0                         df_ax  2025-07-07 07:47:00                     NaN\n",
      "2025-07-07 07:47:00         94.965556         38.107736                        0.0                         df_ax  2025-07-07 07:47:00                     NaN\n",
      "2025-07-07 07:47:00         94.965556         38.107736                        0.0                         df_ax  2025-07-07 07:47:00                     NaN\n",
      "2025-07-07 07:47:00         94.965556         38.107736                        0.0                         df_ax  2025-07-07 07:47:00                     NaN\n",
      "2025-07-07 07:47:00         94.965556         38.107736                        0.0                         df_ax  2025-07-07 07:47:00                     NaN\n",
      "2025-07-07 07:47:00         94.965556         38.107736                        0.0                         df_ax  2025-07-07 07:47:00                     NaN\n",
      "\n",
      "Duplicate timestamps saved to: duplicate_timestamps.csv\n"
     ]
    }
   ],
   "source": [
    "# Summary of duplicate timestamps\n",
    "if not df_duplicate_timestamps.empty:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DUPLICATE TIMESTAMPS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total duplicate rows captured: {len(df_duplicate_timestamps)}\")\n",
    "    print(f\"Number of unique duplicate timestamps: {df_duplicate_timestamps.index.nunique()}\")\n",
    "    \n",
    "    print(\"\\nDuplicates by source DataFrame:\")\n",
    "    source_counts = df_duplicate_timestamps.groupby('Source').size()\n",
    "    for source, count in source_counts.items():\n",
    "        print(f\"  {source}: {count} rows\")\n",
    "    \n",
    "    print(\"\\nUnique timestamps that appear multiple times:\")\n",
    "    unique_dups = sorted(df_duplicate_timestamps.index.unique())\n",
    "    for ts in unique_dups:\n",
    "        print(f\"  {ts.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Show a sample of the data for one duplicate timestamp\n",
    "    print(\"\\nExample: Data for first duplicate timestamp\")\n",
    "    first_dup = unique_dups[0]\n",
    "    sample = df_duplicate_timestamps[df_duplicate_timestamps.index == first_dup]\n",
    "    print(sample.to_string())\n",
    "    \n",
    "    # Optionally save to CSV\n",
    "    csv_path = 'duplicate_timestamps.csv'\n",
    "    df_duplicate_timestamps.to_csv(csv_path)\n",
    "    print(f\"\\nDuplicate timestamps saved to: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45de502d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded plot settings from Pajala_Flöde.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chrini\\AppData\\Local\\Temp\\ipykernel_63012\\1915708140.py:914: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  self.canvas.draw()\n"
     ]
    }
   ],
   "source": [
    "from PyQt6.QtWidgets import QApplication, QMainWindow, QVBoxLayout, QHBoxLayout, QCheckBox, QPushButton, QWidget, QLabel, QComboBox, QDialog, QDialogButtonBox, QSizePolicy\n",
    "from PyQt6.QtGui import QKeySequence, QShortcut, QPalette, QColor\n",
    "from PyQt6.QtCore import Qt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas, NavigationToolbar2QT\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import MO, WeekdayLocator\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import inspect\n",
    "import re\n",
    "def dprint(x): # https://stackoverflow.com/questions/32000934/print-a-variables-name-and-value/57225950#57225950\n",
    "    frame = inspect.currentframe().f_back\n",
    "    s = inspect.getframeinfo(frame).code_context[0]\n",
    "    r = re.search(r\"\\((.*)\\)\", s).group(1)\n",
    "    print(\"{} = {}\".format(r,x))\n",
    "\n",
    "import json\n",
    "\n",
    "def save_plot_settings(settings, filename='Pajala_Flöde.json'):\n",
    "    \"\"\"Save plot axis settings to JSON file.\"\"\"\n",
    "    cleaned_settings = {}\n",
    "    for key, value in settings.items():\n",
    "        if key == 'series_visible':\n",
    "            cleaned_settings[key] = [1 if x else 0 for x in value]\n",
    "        elif isinstance(value, (list, tuple)):\n",
    "            cleaned_settings[key] = [float(x) for x in value]\n",
    "        else:\n",
    "            cleaned_settings[key] = float(value) if value is not None else None\n",
    "    try:\n",
    "        with open(filename, 'w', newline='\\r\\n') as f:\n",
    "            json.dump(cleaned_settings, f, indent=4, separators=(',', ': '))\n",
    "        print(f'Saved plot settings to {filename}')\n",
    "    except Exception as e:\n",
    "        print(f'Warning: could not save plot settings to {filename}: {e}')\n",
    "\n",
    "def load_plot_settings(filename='Pajala_Flöde.json'):\n",
    "    \"\"\"Load plot axis settings from JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            settings = json.load(f)\n",
    "            if 'series_visible' in settings:\n",
    "                settings['series_visible'] = [bool(x) for x in settings['series_visible']]\n",
    "        print(f'Loaded plot settings from {filename}')\n",
    "        return settings\n",
    "    except FileNotFoundError:\n",
    "        print(f'No saved settings found at {filename}')\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f'Warning: could not load plot settings from {filename}: {e}')\n",
    "        return None\n",
    "\n",
    "class ManualXAxisDialog(QDialog):\n",
    "    def __init__(self, parent=None, current_mode=None):\n",
    "        super().__init__(parent)\n",
    "        self.setWindowTitle(\"Manual X-Axis Mode\")\n",
    "        self.combo = QComboBox(self)\n",
    "        self.combo.addItems([\n",
    "            \"Minute\",\n",
    "            \"Hour\",\n",
    "            \"Day\",\n",
    "            \"Week\",\n",
    "            \"Month\",\n",
    "            \"Year\"\n",
    "        ])\n",
    "        if current_mode is not None:\n",
    "            idx = self.combo.findText(current_mode)\n",
    "            if idx >= 0:\n",
    "                self.combo.setCurrentIndex(idx)\n",
    "        layout = QVBoxLayout(self)\n",
    "        layout.addWidget(QLabel(\"Select manual x-axis mode:\"))\n",
    "        layout.addWidget(self.combo)\n",
    "        buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)\n",
    "        buttons.accepted.connect(self.accept)\n",
    "        buttons.rejected.connect(self.reject)\n",
    "        layout.addWidget(buttons)\n",
    "\n",
    "    def get_mode(self):\n",
    "        return self.combo.currentText()\n",
    "\n",
    "class CustomNavigationToolbar(NavigationToolbar2QT):\n",
    "    def __init__(self, canvas, parent=None, plot_window = None):\n",
    "        super().__init__(canvas, parent)\n",
    "        self.plot_window = plot_window\n",
    "        self.addSeparator()\n",
    "        self.addAction('Autoscale', self.autoscale)\n",
    "        self.addSeparator()\n",
    "        self.addAction('Autoscale LY', self.autoscaleLeftY)\n",
    "        self.addSeparator()\n",
    "        self.addAction('Autoscale RY', self.autoscaleRightY)\n",
    "        self.addSeparator()        \n",
    "        self.addAction('Move Left', self.moveLeft)\n",
    "        self.addSeparator()\n",
    "        self.addAction('Move Right', self.moveRight)\n",
    "        self.addSeparator()\n",
    "        self.addAction('Reset X', self.plot_window.resetXAxis)\n",
    "        self.addSeparator()\n",
    "\n",
    "        # Add Manual/Auto X-Axis toggle button\n",
    "        self.manual_xaxis_btn = QPushButton(\"Manual X-Axis\")\n",
    "        self.manual_xaxis_btn.setCheckable(True)\n",
    "        self.manual_xaxis_btn.clicked.connect(self.toggle_manual_xaxis)\n",
    "        self.addWidget(self.manual_xaxis_btn)\n",
    "\n",
    "        # Add keyboard shortcuts\n",
    "        self.shortcut_pan = QShortcut(QKeySequence(\"P\"), self)\n",
    "        self.shortcut_pan.activated.connect(self.pan)\n",
    "\n",
    "        self.shortcut_zoom = QShortcut(QKeySequence(\"Z\"), self)\n",
    "        self.shortcut_zoom.activated.connect(self.zoom)\n",
    "\n",
    "        # Add QLabel to display xAxisLen\n",
    "        self.xAxisLenLabel = QLabel(\"xAxisLen: N/A\")\n",
    "        self.addWidget(self.xAxisLenLabel)\n",
    "        self.addSeparator()\n",
    "\n",
    "        # Add QLabel to display mode (Auto/Manual)\n",
    "        self.modeLabel = QLabel(\"Mode: Auto\")\n",
    "        self.addWidget(self.modeLabel)\n",
    "        self.addSeparator()\n",
    "\n",
    "        # Add QLabel to display locator settings\n",
    "        self.locatorLabel = QLabel(\"Locator: N/A\")\n",
    "        self.addWidget(self.locatorLabel)\n",
    "\n",
    "    def toggle_manual_xaxis(self):\n",
    "        if self.manual_xaxis_btn.isChecked():\n",
    "            # Show dialog to select manual mode\n",
    "            dlg = ManualXAxisDialog(self, getattr(self.plot_window, 'manual_xaxis_mode', None))\n",
    "            if dlg.exec() == QDialog.DialogCode.Accepted:\n",
    "                mode = dlg.get_mode()\n",
    "                self.plot_window.manual_xaxis_mode = mode\n",
    "                self.plot_window.manual_xaxis = True\n",
    "                self.manual_xaxis_btn.setText(\"Auto X-Axis\")\n",
    "                self.modeLabel.setText(f\"Mode: Manual ({mode})\")\n",
    "            else:\n",
    "                # Cancelled, revert button\n",
    "                self.manual_xaxis_btn.setChecked(False)\n",
    "                return\n",
    "        else:\n",
    "            self.plot_window.manual_xaxis = False\n",
    "            self.plot_window.manual_xaxis_mode = None\n",
    "            self.manual_xaxis_btn.setText(\"Manual X-Axis\")\n",
    "            self.modeLabel.setText(\"Mode: Auto\")\n",
    "        self.plot_window.reformatXAxis()\n",
    "        self.plot_window.canvas.draw()\n",
    "        self.update_locator_info()\n",
    "\n",
    "    def autoscale(self):\n",
    "        ax1 = self.plot_window.axL\n",
    "        ax1.autoscale(axis='both')\n",
    "        self.canvas.draw()\n",
    "        self.update_xAxisLen()\n",
    "        self.plot_window.save_current_settings()\n",
    "\n",
    "    def autoscaleLeftY(self):\n",
    "        df_axL = self.plot_window.df_axL\n",
    "        series_visibleLeftY = self.plot_window.series_visible[:len(df_axL.columns)]\n",
    "        if not any(series_visibleLeftY):\n",
    "            return\n",
    "        # Get current x-axis limits\n",
    "        xlim = self.plot_window.axL.get_xlim()\n",
    "        xlim = [mdates.num2date(x).replace(tzinfo=None) for x in xlim]\n",
    "        selected_columns = df_axL[(df_axL.index >= xlim[0]) & (df_axL.index <= xlim[1])]\n",
    "        selected_columns = selected_columns.loc[:, series_visibleLeftY]\n",
    "        if selected_columns.empty:\n",
    "            return\n",
    "        ylim = (selected_columns.min().min(), selected_columns.max().max())\n",
    "        self.plot_window.axL.set_ylim(ylim)\n",
    "        self.canvas.draw()\n",
    "        self.plot_window.save_current_settings()\n",
    "\n",
    "    def autoscaleRightY(self):\n",
    "        # Guard if there is no right-axis data\n",
    "        df_axR = self.plot_window.df_axR\n",
    "        if df_axR is None or df_axR.empty:\n",
    "            return\n",
    "        # compute visible columns for right axis\n",
    "        df_axL = self.plot_window.df_axL\n",
    "        total_left = len(df_axL.columns)\n",
    "        series_visibleRightY = self.plot_window.series_visible[total_left: total_left + len(df_axR.columns)]\n",
    "        if not any(series_visibleRightY):\n",
    "            return\n",
    "        # Get current x-axis limits\n",
    "        xlim = self.plot_window.axR.get_xlim()\n",
    "        xlim = [mdates.num2date(x).replace(tzinfo=None) for x in xlim]\n",
    "        selected_columns = df_axR[(df_axR.index >= xlim[0]) & (df_axR.index <= xlim[1])]\n",
    "        selected_columns = selected_columns.loc[:, series_visibleRightY]\n",
    "        if selected_columns.empty:\n",
    "            return\n",
    "        ylim = (selected_columns.min().min(), selected_columns.max().max())\n",
    "        self.plot_window.axR.set_ylim(ylim)\n",
    "        self.canvas.draw()\n",
    "        self.plot_window.save_current_settings()\n",
    "\n",
    "    def pan(self):\n",
    "        super().pan()\n",
    "        self.plot_window.reformatXAxis()\n",
    "        self.update_xAxisLen()\n",
    "        self.update_locator_info()\n",
    "        self.plot_window.save_current_settings()\n",
    "\n",
    "    def zoom(self):\n",
    "        super().zoom()\n",
    "        self.plot_window.reformatXAxis()\n",
    "        self.update_xAxisLen()\n",
    "        self.update_locator_info()\n",
    "        self.plot_window.save_current_settings()\n",
    "\n",
    "    def update_xAxisLen(self):\n",
    "        ax1 = self.canvas.figure.gca()\n",
    "        xlim = ax1.get_xlim()\n",
    "        xAxisLen = xlim[1] - xlim[0]\n",
    "        if hasattr(self, 'xAxisLenLabel') and self.xAxisLenLabel is not None:\n",
    "            self.xAxisLenLabel.setText(f\"xAxisLen: {xAxisLen:.2f}\")\n",
    "\n",
    "    def update_locator_info(self):\n",
    "        \"\"\"Update the locator label with current major/minor locator settings\"\"\"\n",
    "        if hasattr(self, 'locatorLabel') and self.locatorLabel is not None:\n",
    "            if hasattr(self.plot_window, 'current_locator_info'):\n",
    "                self.locatorLabel.setText(self.plot_window.current_locator_info)\n",
    "            else:\n",
    "                self.locatorLabel.setText(\"Locator: N/A\")\n",
    "    \n",
    "    def moveLeft(self):\n",
    "        xlim = self.plot_window.axL.get_xlim()\n",
    "        step = (xlim[1] - xlim[0]) * 0.25  # Move 25% of the current x-axis range\n",
    "        self.plot_window.axL.set_xlim(xlim[0] - step, xlim[1] - step)\n",
    "        self.canvas.draw()\n",
    "        self.update_xAxisLen()\n",
    "        self.plot_window.save_current_settings()\n",
    "\n",
    "    def moveRight(self):\n",
    "        xlim = self.plot_window.axL.get_xlim()\n",
    "        step = (xlim[1] - xlim[0]) * 0.25  # Move 25% of the current x-axis range\n",
    "        self.plot_window.axL.set_xlim(xlim[0] + step, xlim[1] + step)\n",
    "        self.canvas.draw()\n",
    "        self.update_xAxisLen()\n",
    "        self.plot_window.save_current_settings()\n",
    "\n",
    "class InteractivePlotWindow(QMainWindow):\n",
    "    def __init__(self, df_axL, df_axL_Title = None, df_axR=None, df_axR_Title = None, WindowTitle = None, initial_visible=None, settings_file=None):\n",
    "        super().__init__()\n",
    "        if WindowTitle is None:\n",
    "            self.setWindowTitle(\"Interactive Plot\")\n",
    "        else:\n",
    "            self.setWindowTitle(WindowTitle)\n",
    "\n",
    "        # Store the DataFrames (ensure df_axR is a DataFrame if None)\n",
    "        self.df_axL = df_axL\n",
    "        self.df_axR = df_axR if df_axR is not None else pd.DataFrame()\n",
    "        self.df_axL_Title = df_axL_Title\n",
    "        self.df_axR_Title = df_axR_Title\n",
    "        \n",
    "        # Settings file path (default or custom)\n",
    "        self.settings_file = settings_file if settings_file is not None else 'Pajala_Flöde.json'\n",
    "        \n",
    "        # Flag to check if it's the initial plot\n",
    "        self.initial_plot = True\n",
    "\n",
    "        # Manual/auto x-axis state\n",
    "        self.manual_xaxis = False\n",
    "        self.manual_xaxis_mode = None\n",
    "\n",
    "        # Auto-update state for series visibility\n",
    "        self.auto_update = True\n",
    "\n",
    "        # Dark mode state\n",
    "        self.dark_mode = False\n",
    "\n",
    "        # Create central widget\n",
    "        self.central_widget = QWidget()\n",
    "        self.setCentralWidget(self.central_widget)\n",
    "        layout = QVBoxLayout(self.central_widget)\n",
    "\n",
    "        # Create Figure and Canvas\n",
    "        # Use constrained_layout and tighter subplot margins to reduce border whitespace\n",
    "        self.fig = Figure(constrained_layout=True)\n",
    "        self.canvas = FigureCanvas(self.fig)\n",
    "        self.toolbar = CustomNavigationToolbar(self.canvas, self, plot_window=self)\n",
    "\n",
    "        # Determine columns and initial visibility\n",
    "        left_cols = list(self.df_axL.columns)\n",
    "        right_cols = list(self.df_axR.columns) if (self.df_axR is not None and not self.df_axR.empty) else []\n",
    "        all_cols = left_cols + right_cols\n",
    "\n",
    "        # Try to load saved settings before setting up visibility and checkboxes\n",
    "        self.saved_settings = load_plot_settings(self.settings_file)\n",
    "        \n",
    "        # Set up initial visibility state\n",
    "        if self.saved_settings and 'series_visible' in self.saved_settings and len(self.saved_settings['series_visible']) == len(all_cols):\n",
    "            # Use saved visibility if available and matches column count\n",
    "            self.series_visible = [bool(x) for x in self.saved_settings['series_visible']]\n",
    "        else:\n",
    "            # Fall back to initial_visible parameter\n",
    "            if initial_visible is None:\n",
    "                self.series_visible = [True] * len(all_cols)\n",
    "            elif isinstance(initial_visible, (list, tuple)) and len(initial_visible) == len(all_cols):\n",
    "                # Convert numeric 1/0 or booleans to booleans\n",
    "                self.series_visible = [bool(x) for x in initial_visible]\n",
    "            else:\n",
    "                # Treat initial_visible as list of column names to show\n",
    "                try:\n",
    "                    visible_set = set(initial_visible)\n",
    "                    self.series_visible = [ (col in visible_set) for col in all_cols ]\n",
    "                except Exception:\n",
    "                    # fallback to all True\n",
    "                    self.series_visible = [True] * len(all_cols)\n",
    "\n",
    "        # Initialize checkboxes list\n",
    "        self.checkboxes = []\n",
    "        \n",
    "        # Add auto-update toggle and manual update button at the top\n",
    "        control_layout = QHBoxLayout()\n",
    "        self.auto_update_checkbox = QCheckBox(\"Auto-update chart\")\n",
    "        self.auto_update_checkbox.setChecked(True)\n",
    "        self.auto_update_checkbox.stateChanged.connect(self.toggle_auto_update)\n",
    "        control_layout.addWidget(self.auto_update_checkbox)\n",
    "        \n",
    "        self.manual_update_btn = QPushButton(\"Update Chart\")\n",
    "        self.manual_update_btn.clicked.connect(self.manual_update_chart)\n",
    "        self.manual_update_btn.setEnabled(False)  # Initially disabled since auto-update is on\n",
    "        control_layout.addWidget(self.manual_update_btn)\n",
    "        \n",
    "        self.dark_mode_btn = QPushButton(\"Dark Mode\")\n",
    "        self.dark_mode_btn.setCheckable(True)\n",
    "        self.dark_mode_btn.clicked.connect(self.toggle_dark_mode)\n",
    "        control_layout.addWidget(self.dark_mode_btn)\n",
    "        \n",
    "        control_layout.addStretch()\n",
    "        \n",
    "        layout.addLayout(control_layout)\n",
    "        layout.addWidget(self.toolbar)\n",
    "        layout.addWidget(self.canvas)\n",
    "\n",
    "        # Build checkboxes below the chart with left and right sections in framed boxes\n",
    "        from PyQt6.QtWidgets import QGridLayout, QFrame\n",
    "        \n",
    "        # Create horizontal layout for left and right framed sections\n",
    "        series_layout = QHBoxLayout()\n",
    "        \n",
    "        # Number of columns per row in the grid\n",
    "        num_cols_per_row = 8\n",
    "        \n",
    "        # LEFT AXIS SECTION (Blue frame)\n",
    "        if len(left_cols) > 0:\n",
    "            left_frame = QFrame()\n",
    "            left_frame.setStyleSheet(\"\"\"\n",
    "                QFrame {\n",
    "                    background-color: #e8f4f8;\n",
    "                    border: 2px solid #0066cc;\n",
    "                    border-radius: 5px;\n",
    "                    padding: 5px;\n",
    "                }\n",
    "            \"\"\")\n",
    "            left_layout = QGridLayout(left_frame)\n",
    "            left_layout.setSpacing(2)\n",
    "            left_layout.setContentsMargins(5, 5, 5, 5)\n",
    "            \n",
    "            for i, col in enumerate(left_cols):\n",
    "                row = i // num_cols_per_row\n",
    "                col_pos = i % num_cols_per_row\n",
    "                checkbox = QCheckBox(f\"{col}\")\n",
    "                checkbox.setStyleSheet(\"\"\"\n",
    "                    QCheckBox { \n",
    "                        background-color: transparent; \n",
    "                        color: #003366;\n",
    "                        spacing: 5px;\n",
    "                    }\n",
    "                    QCheckBox::indicator {\n",
    "                        width: 13px;\n",
    "                        height: 13px;\n",
    "                        border: 2px solid #003366;\n",
    "                        border-radius: 3px;\n",
    "                        background-color: white;\n",
    "                    }\n",
    "                    QCheckBox::indicator:checked {\n",
    "                        background-color: #0066cc;\n",
    "                        border: 2px solid #003366;\n",
    "                    }\n",
    "                \"\"\")\n",
    "                checkbox.blockSignals(True)\n",
    "                checkbox.setChecked(bool(self.series_visible[i]))\n",
    "                checkbox.blockSignals(False)\n",
    "                checkbox.stateChanged.connect(self.create_toggle_function(i))\n",
    "                left_layout.addWidget(checkbox, row, col_pos)\n",
    "                self.checkboxes.append(checkbox)\n",
    "            \n",
    "            # Set size policy to minimize vertical expansion\n",
    "            left_frame.setSizePolicy(QSizePolicy.Policy.Preferred, QSizePolicy.Policy.Maximum)\n",
    "            series_layout.addWidget(left_frame)\n",
    "        \n",
    "        # RIGHT AXIS SECTION (Orange frame)\n",
    "        if len(right_cols) > 0:\n",
    "            right_frame = QFrame()\n",
    "            right_frame.setStyleSheet(\"\"\"\n",
    "                QFrame {\n",
    "                    background-color: #fff5e6;\n",
    "                    border: 2px solid #cc6600;\n",
    "                    border-radius: 5px;\n",
    "                    padding: 5px;\n",
    "                }\n",
    "            \"\"\")\n",
    "            right_layout = QGridLayout(right_frame)\n",
    "            right_layout.setSpacing(2)\n",
    "            right_layout.setContentsMargins(5, 5, 5, 5)\n",
    "            \n",
    "            for i, col in enumerate(right_cols):\n",
    "                row = i // num_cols_per_row\n",
    "                col_pos = i % num_cols_per_row\n",
    "                checkbox = QCheckBox(f\"{col}\")\n",
    "                checkbox.setStyleSheet(\"\"\"\n",
    "                    QCheckBox { \n",
    "                        background-color: transparent; \n",
    "                        color: #663300;\n",
    "                        spacing: 5px;\n",
    "                    }\n",
    "                    QCheckBox::indicator {\n",
    "                        width: 13px;\n",
    "                        height: 13px;\n",
    "                        border: 2px solid #663300;\n",
    "                        border-radius: 3px;\n",
    "                        background-color: white;\n",
    "                    }\n",
    "                    QCheckBox::indicator:checked {\n",
    "                        background-color: #cc6600;\n",
    "                        border: 2px solid #663300;\n",
    "                    }\n",
    "                \"\"\")\n",
    "                checkbox.blockSignals(True)\n",
    "                checkbox.setChecked(bool(self.series_visible[len(left_cols) + i]))\n",
    "                checkbox.blockSignals(False)\n",
    "                checkbox.stateChanged.connect(self.create_toggle_function(len(left_cols) + i))\n",
    "                right_layout.addWidget(checkbox, row, col_pos)\n",
    "                self.checkboxes.append(checkbox)\n",
    "            \n",
    "            # Set size policy to minimize vertical expansion\n",
    "            right_frame.setSizePolicy(QSizePolicy.Policy.Preferred, QSizePolicy.Policy.Maximum)\n",
    "            series_layout.addWidget(right_frame)\n",
    "\n",
    "        layout.addLayout(series_layout)\n",
    "        \n",
    "        # Initialize crosshair state (click-to-place)\n",
    "        self.crosshair_vline = None\n",
    "        self.crosshair_hline = None\n",
    "        self.crosshair_hline_right = None\n",
    "        self.mouse_pressed = False\n",
    "        \n",
    "        # Connect mouse events for click-and-drag crosshair\n",
    "        self.canvas.mpl_connect('button_press_event', self.on_mouse_press)\n",
    "        self.canvas.mpl_connect('button_release_event', self.on_mouse_release)\n",
    "        self.canvas.mpl_connect('motion_notify_event', self.on_mouse_move)\n",
    "        \n",
    "        # Initial plot\n",
    "        self.plot()\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        \"\"\"Save settings when window is closed\"\"\"\n",
    "        self.save_current_settings()\n",
    "        super().closeEvent(event)\n",
    "\n",
    "    def save_current_settings(self):\n",
    "        \"\"\"Save current axis limits and other settings\"\"\"\n",
    "        if not hasattr(self, 'axL'):\n",
    "            return\n",
    "            \n",
    "        settings = {\n",
    "            'axLxlim': list(self.axL.get_xlim()),\n",
    "            'axLylim': list(self.axL.get_ylim()),\n",
    "            'series_visible': self.series_visible\n",
    "        }\n",
    "        \n",
    "        if self.df_axR is not None and not self.df_axR.empty and self.axR is not None:\n",
    "            settings.update({\n",
    "                'axRxlim': list(self.axR.get_xlim()),\n",
    "                'axRylim': list(self.axR.get_ylim())\n",
    "            })\n",
    "            \n",
    "        save_plot_settings(settings, self.settings_file)\n",
    "\n",
    "    def create_toggle_function(self, index):\n",
    "        # Accept the state argument from stateChanged signal and set the visibility directly.\n",
    "        def toggle(state):\n",
    "            # state is an int/Qt.Checked; convert to boolean\n",
    "            self.series_visible[index] = bool(state)\n",
    "            # Only re-plot and save if auto-update is enabled\n",
    "            if self.auto_update:\n",
    "                self.plot()\n",
    "                self.save_current_settings()\n",
    "        return toggle\n",
    "\n",
    "    def toggle_auto_update(self, state):\n",
    "        \"\"\"Toggle auto-update mode for series visibility changes.\"\"\"\n",
    "        self.auto_update = bool(state)\n",
    "        self.manual_update_btn.setEnabled(not self.auto_update)\n",
    "        \n",
    "    def manual_update_chart(self):\n",
    "        \"\"\"Manually trigger chart update when auto-update is disabled.\"\"\"\n",
    "        self.plot()\n",
    "        self.save_current_settings()\n",
    "\n",
    "    def toggle_dark_mode(self):\n",
    "        \"\"\"Toggle between light and dark mode for the chart.\"\"\"\n",
    "        self.dark_mode = self.dark_mode_btn.isChecked()\n",
    "        \n",
    "    def _custom_format_coord(self, x, y):\n",
    "        \"\"\"Custom coordinate formatter that always shows date as YYYY-MM-DD HH:MM\"\"\"\n",
    "        # CRITICAL: Must be set on BOTH axL and axR (if present) since the top-most\n",
    "        # axis (axR from twinx) handles mouse events and coordinate display\n",
    "        \n",
    "        # Always format as YYYY-MM-DD HH:MM regardless of x-axis mode\n",
    "        xstr = \"\"\n",
    "        try:\n",
    "            dt = mdates.num2date(x)\n",
    "            # Remove timezone information if present\n",
    "            if dt.tzinfo is not None:\n",
    "                dt = dt.replace(tzinfo=None)\n",
    "            xstr = dt.strftime('%Y-%m-%d %H:%M')\n",
    "        except Exception as e:\n",
    "            # Fallback: try manual conversion\n",
    "            try:\n",
    "                from datetime import datetime, timedelta\n",
    "                # Matplotlib date is days since 0001-01-01 UTC\n",
    "                dt = datetime.fromordinal(int(x)) + timedelta(days=x%1) - timedelta(days=366)\n",
    "                xstr = dt.strftime('%Y-%m-%d %H:%M')\n",
    "            except Exception as e2:\n",
    "                xstr = f\"{x:.2f}\"\n",
    "        \n",
    "        # y parameter is the mouse y-coordinate in the axis that's handling the event\n",
    "        # If axR exists, it's on top and handles events, so y is in right-axis scale\n",
    "        # We need to transform it to left-axis scale for yL\n",
    "        yL = y\n",
    "        yR = None\n",
    "        \n",
    "        if self.df_axR is not None and not self.df_axR.empty and hasattr(self, 'axR') and self.axR is not None:\n",
    "            # When right axis exists, y is in right-axis coordinates\n",
    "            # Transform to left axis coordinates\n",
    "            try:\n",
    "                # Get the y-limits of both axes\n",
    "                ylim_R = self.axR.get_ylim()\n",
    "                ylim_L = self.axL.get_ylim()\n",
    "                \n",
    "                # Normalize y from right axis scale (0 to 1)\n",
    "                y_norm = (y - ylim_R[0]) / (ylim_R[1] - ylim_R[0])\n",
    "                \n",
    "                # Transform to left axis scale\n",
    "                yL = ylim_L[0] + y_norm * (ylim_L[1] - ylim_L[0])\n",
    "                yR = y  # Original y is already in right-axis scale\n",
    "            except Exception:\n",
    "                yL = y\n",
    "                yR = None\n",
    "        \n",
    "        # Return formatted string with explicit x= prefix to ensure it's clear\n",
    "        if yR is not None:\n",
    "            return f\"x={xstr}  yL={yL:.2f}  yR={yR:.2f}\"\n",
    "        else:\n",
    "            return f\"x={xstr}  y={yL:.2f}\"\n",
    "\n",
    "    def on_mouse_press(self, event):\n",
    "        \"\"\"Handle mouse button press - start drawing crosshair.\"\"\"\n",
    "        if event.inaxes in [self.axL, self.axR] and event.xdata is not None and event.ydata is not None:\n",
    "            self.mouse_pressed = True\n",
    "            self.update_crosshair(event)\n",
    "\n",
    "    def on_mouse_release(self, event):\n",
    "        \"\"\"Handle mouse button release - stop updating crosshair but keep it visible.\"\"\"\n",
    "        self.mouse_pressed = False\n",
    "\n",
    "    def on_mouse_move(self, event):\n",
    "        \"\"\"Update crosshair position when mouse moves while button is pressed.\"\"\"\n",
    "        if self.mouse_pressed and event.inaxes in [self.axL, self.axR]:\n",
    "            self.update_crosshair(event)\n",
    "\n",
    "    def update_crosshair(self, event):\n",
    "        \"\"\"Draw or update crosshair at the current mouse position.\"\"\"\n",
    "        if event.xdata is None or event.ydata is None:\n",
    "            return\n",
    "        \n",
    "        # Remove old crosshair lines if they exist\n",
    "        if self.crosshair_vline is not None:\n",
    "            self.crosshair_vline.remove()\n",
    "        if self.crosshair_hline is not None:\n",
    "            self.crosshair_hline.remove()\n",
    "        if self.crosshair_hline_right is not None:\n",
    "            self.crosshair_hline_right.remove()\n",
    "        \n",
    "        # Create new crosshair lines at current position\n",
    "        self.crosshair_vline = self.axL.axvline(event.xdata, color='red', linestyle='--', linewidth=0.8, alpha=0.8, zorder=100)\n",
    "        \n",
    "        # Create horizontal line on the appropriate axis\n",
    "        if event.inaxes == self.axR:\n",
    "            self.crosshair_hline_right = self.axR.axhline(event.ydata, color='red', linestyle='--', linewidth=0.8, alpha=0.8, zorder=100)\n",
    "            self.crosshair_hline = None\n",
    "        else:\n",
    "            self.crosshair_hline = self.axL.axhline(event.ydata, color='red', linestyle='--', linewidth=0.8, alpha=0.8, zorder=100)\n",
    "            self.crosshair_hline_right = None\n",
    "        \n",
    "        self.canvas.draw_idle()\n",
    "\n",
    "    def toggle_dark_mode(self):\n",
    "        if self.dark_mode:\n",
    "            plt.style.use('dark_background')\n",
    "            self.dark_mode_btn.setText(\"Light Mode\")\n",
    "            \n",
    "            # Set Windows 11 dark mode title bar\n",
    "            try:\n",
    "                import ctypes\n",
    "                HWND = self.winId().__int__()\n",
    "                DWMWA_USE_IMMERSIVE_DARK_MODE = 20\n",
    "                value = ctypes.c_int(1)  # 1 for dark mode, 0 for light\n",
    "                ctypes.windll.dwmapi.DwmSetWindowAttribute(HWND, DWMWA_USE_IMMERSIVE_DARK_MODE, ctypes.byref(value), ctypes.sizeof(value))\n",
    "            except Exception as e:\n",
    "                print(f\"Could not set Windows dark mode title bar: {e}\")\n",
    "            \n",
    "            # Set figure and canvas background to dark\n",
    "            self.fig.patch.set_facecolor('#202020')\n",
    "            self.canvas.setStyleSheet(\"background-color: #202020;\")\n",
    "            \n",
    "            # Create dark palette\n",
    "            dark_palette = QPalette()\n",
    "            dark_palette.setColor(QPalette.ColorRole.Window, QColor(43, 43, 43))\n",
    "            dark_palette.setColor(QPalette.ColorRole.WindowText, QColor(255, 255, 255))\n",
    "            dark_palette.setColor(QPalette.ColorRole.Base, QColor(60, 60, 60))\n",
    "            dark_palette.setColor(QPalette.ColorRole.AlternateBase, QColor(43, 43, 43))\n",
    "            dark_palette.setColor(QPalette.ColorRole.ToolTipBase, QColor(255, 255, 255))\n",
    "            dark_palette.setColor(QPalette.ColorRole.ToolTipText, QColor(255, 255, 255))\n",
    "            dark_palette.setColor(QPalette.ColorRole.Text, QColor(255, 255, 255))\n",
    "            dark_palette.setColor(QPalette.ColorRole.Button, QColor(60, 60, 60))\n",
    "            dark_palette.setColor(QPalette.ColorRole.ButtonText, QColor(255, 255, 255))\n",
    "            dark_palette.setColor(QPalette.ColorRole.BrightText, QColor(255, 0, 0))\n",
    "            dark_palette.setColor(QPalette.ColorRole.Link, QColor(42, 130, 218))\n",
    "            dark_palette.setColor(QPalette.ColorRole.Highlight, QColor(42, 130, 218))\n",
    "            dark_palette.setColor(QPalette.ColorRole.HighlightedText, QColor(0, 0, 0))\n",
    "            self.setPalette(dark_palette)\n",
    "            \n",
    "            # Set dark theme stylesheet for the entire window including toolbar\n",
    "            dark_stylesheet = \"\"\"\n",
    "                QMainWindow, QWidget {\n",
    "                    background-color: #2b2b2b;\n",
    "                    color: #ffffff;\n",
    "                }\n",
    "                QToolBar {\n",
    "                    background-color: #2b2b2b;\n",
    "                    border: none;\n",
    "                    spacing: 3px;\n",
    "                }\n",
    "                QPushButton {\n",
    "                    background-color: #3c3c3c;\n",
    "                    color: #ffffff;\n",
    "                    border: 1px solid #555555;\n",
    "                    padding: 5px;\n",
    "                    border-radius: 3px;\n",
    "                }\n",
    "                QPushButton:hover {\n",
    "                    background-color: #4c4c4c;\n",
    "                }\n",
    "                QPushButton:pressed {\n",
    "                    background-color: #2c2c2c;\n",
    "                }\n",
    "                QPushButton:checked {\n",
    "                    background-color: #0d5a8f;\n",
    "                }\n",
    "                QCheckBox {\n",
    "                    color: #ffffff;\n",
    "                }\n",
    "                QLabel {\n",
    "                    color: #ffffff;\n",
    "                }\n",
    "                QToolButton {\n",
    "                    background-color: #3c3c3c;\n",
    "                    color: #ffffff;\n",
    "                    border: 1px solid #555555;\n",
    "                    padding: 3px;\n",
    "                    border-radius: 2px;\n",
    "                }\n",
    "                QToolButton:hover {\n",
    "                    background-color: #4c4c4c;\n",
    "                }\n",
    "                QToolButton:pressed {\n",
    "                    background-color: #2c2c2c;\n",
    "                }\n",
    "                QLineEdit {\n",
    "                    background-color: #3c3c3c;\n",
    "                    color: #ffffff;\n",
    "                    border: 1px solid #555555;\n",
    "                    padding: 2px;\n",
    "                }\n",
    "                QComboBox {\n",
    "                    background-color: #3c3c3c;\n",
    "                    color: #ffffff;\n",
    "                    border: 1px solid #555555;\n",
    "                    padding: 2px;\n",
    "                }\n",
    "                QComboBox:hover {\n",
    "                    background-color: #4c4c4c;\n",
    "                }\n",
    "                QComboBox::drop-down {\n",
    "                    border: none;\n",
    "                }\n",
    "                QSpinBox {\n",
    "                    background-color: #3c3c3c;\n",
    "                    color: #ffffff;\n",
    "                    border: 1px solid #555555;\n",
    "                }\n",
    "            \"\"\"\n",
    "            self.setStyleSheet(dark_stylesheet)\n",
    "            # Force update all widgets in the toolbar\n",
    "            if hasattr(self, 'toolbar'):\n",
    "                # Apply styling to toolbar and all its child widgets\n",
    "                toolbar_stylesheet = \"\"\"\n",
    "                    QToolBar {\n",
    "                        background-color: #2b2b2b;\n",
    "                        border: none;\n",
    "                        spacing: 3px;\n",
    "                    }\n",
    "                    QToolBar QToolButton {\n",
    "                        background-color: #3c3c3c;\n",
    "                        color: #ffffff;\n",
    "                        border: 1px solid #555555;\n",
    "                        padding: 3px;\n",
    "                    }\n",
    "                    QToolBar QToolButton:hover {\n",
    "                        background-color: #4c4c4c;\n",
    "                    }\n",
    "                    QToolBar QLabel {\n",
    "                        color: #ffffff;\n",
    "                        background-color: #2b2b2b;\n",
    "                    }\n",
    "                    QToolBar QPushButton {\n",
    "                        background-color: #3c3c3c;\n",
    "                        color: #ffffff;\n",
    "                        border: 1px solid #555555;\n",
    "                        padding: 3px;\n",
    "                    }\n",
    "                    QToolBar QPushButton:hover {\n",
    "                        background-color: #4c4c4c;\n",
    "                    }\n",
    "                \"\"\"\n",
    "                self.toolbar.setStyleSheet(toolbar_stylesheet)\n",
    "        else:\n",
    "            plt.style.use('default')\n",
    "            self.dark_mode_btn.setText(\"Dark Mode\")\n",
    "            \n",
    "            # Set Windows 11 light mode title bar\n",
    "            try:\n",
    "                import ctypes\n",
    "                HWND = self.winId().__int__()\n",
    "                DWMWA_USE_IMMERSIVE_DARK_MODE = 20\n",
    "                value = ctypes.c_int(0)  # 0 for light mode\n",
    "                ctypes.windll.dwmapi.DwmSetWindowAttribute(HWND, DWMWA_USE_IMMERSIVE_DARK_MODE, ctypes.byref(value), ctypes.sizeof(value))\n",
    "            except Exception as e:\n",
    "                print(f\"Could not set Windows light mode title bar: {e}\")\n",
    "            \n",
    "            # Reset figure and canvas background to light\n",
    "            self.fig.patch.set_facecolor('white')\n",
    "            self.canvas.setStyleSheet(\"background-color: white;\")\n",
    "            \n",
    "            # Reset to default light theme and palette\n",
    "            self.setPalette(QApplication.style().standardPalette())\n",
    "            self.setStyleSheet(\"\")\n",
    "            \n",
    "            # Reset toolbar style\n",
    "            if hasattr(self, 'toolbar'):\n",
    "                self.toolbar.setStyleSheet(\"\")\n",
    "                self.toolbar.setPalette(QApplication.style().standardPalette())\n",
    "        \n",
    "        self.plot()\n",
    "        self.save_current_settings()\n",
    "\n",
    "    def plot(self):\n",
    "        # Save the axis title and labels\n",
    "        title = self.axL.get_title() if hasattr(self, 'axL') else ''\n",
    "        xlabel = self.axL.get_xlabel() if hasattr(self, 'axL') else ''\n",
    "        ylabel = self.axL.get_ylabel() if hasattr(self, 'axL') else ''\n",
    "\n",
    "        if not self.initial_plot:\n",
    "            try:\n",
    "                self.axLxlim = self.axL.get_xlim()\n",
    "                self.axLylim = self.axL.get_ylim()\n",
    "                if self.df_axR is not None and not self.df_axR.empty and self.axR is not None:\n",
    "                    self.axRxlim = self.axR.get_xlim()\n",
    "                    self.axRylim = self.axR.get_ylim()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Clear the axes\n",
    "        self.fig.clear()\n",
    "        self.axL = self.fig.add_subplot(111)\n",
    "\n",
    "        # Set custom coordinate formatter on left axis\n",
    "        # NOTE: This will be overridden if we create a right axis (twinx), \n",
    "        # so we must also set it on axR later\n",
    "        self.axL.format_coord = self._custom_format_coord\n",
    "\n",
    "        # Restore the axis title and labels\n",
    "        self.axL.set_title(title)\n",
    "        self.axL.set_xlabel(xlabel)\n",
    "        self.axL.set_ylabel(ylabel)\n",
    "\n",
    "        self.axL.grid(visible=True, which='major', axis='both', color='grey')\n",
    "        self.axL.grid(visible=True, which='minor', axis='both', color='lightgrey')\n",
    "        self.axL.tick_params(which='minor', labelcolor='lightgrey')\n",
    "        self.axL.tick_params(axis='x', rotation=90, which='both')\n",
    "        if self.df_axL_Title:\n",
    "            self.axL.set_ylabel(self.df_axL_Title)\n",
    "\n",
    "        # Generate a color cycle for all series (left + right)\n",
    "        # Use darker colors for better visibility on white background\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.colors as mcolors\n",
    "        total_series = len(self.df_axL.columns) + (len(self.df_axR.columns) if self.df_axR is not None and not self.df_axR.empty else 0)\n",
    "        \n",
    "        # Create darker color palette by using Set1, Dark2, and tab10 which have more saturated colors\n",
    "        if total_series <= 9:\n",
    "            colors = [plt.cm.Set1(i) for i in range(total_series)]\n",
    "        elif total_series <= 17:\n",
    "            colors = [plt.cm.Set1(i % 9) for i in range(9)] + [plt.cm.Dark2(i % 8) for i in range(total_series - 9)]\n",
    "        else:\n",
    "            # For more series, combine Set1, Dark2, and tab10\n",
    "            colors = ([plt.cm.Set1(i % 9) for i in range(9)] + \n",
    "                     [plt.cm.Dark2(i % 8) for i in range(8)] +\n",
    "                     [plt.cm.tab10(i % 10) for i in range(max(0, total_series - 17))])\n",
    "        color_index = 0\n",
    "\n",
    "        # Plot left-axis columns\n",
    "        for i, col in enumerate(self.df_axL.columns):\n",
    "            if self.series_visible[i]:\n",
    "                self.axL.plot(self.df_axL.index, self.df_axL[col], label=col, alpha=0.5, color=colors[color_index])\n",
    "            color_index += 1\n",
    "\n",
    "        handles, labels = self.axL.get_legend_handles_labels()\n",
    "\n",
    "        # Reset right axis\n",
    "        self.axR = None\n",
    "        if self.df_axR is not None and not self.df_axR.empty:\n",
    "            self.axR = self.axL.twinx()\n",
    "            # CRITICAL: Set format_coord on axR too since it's on top and handles mouse events\n",
    "            self.axR.format_coord = self._custom_format_coord\n",
    "            \n",
    "            # Add separator between left and right axis series in legend\n",
    "            if handles:  # Only add separator if there are left axis items\n",
    "                from matplotlib.lines import Line2D\n",
    "                separator = Line2D([0], [0], color='none', label='─────────────')\n",
    "                handles.append(separator)\n",
    "                labels.append('─────────────')\n",
    "            \n",
    "            for i, col in enumerate(self.df_axR.columns, start=len(self.df_axL.columns)):\n",
    "                if self.series_visible[i]:\n",
    "                    # align on left x index (assumes same index or compatible)\n",
    "                    self.axR.plot(self.df_axL.index, self.df_axR[col], label=col, alpha=0.5, color=colors[color_index])\n",
    "                color_index += 1\n",
    "            if self.df_axR_Title:\n",
    "                self.axR.set_ylabel(self.df_axR_Title)\n",
    "\n",
    "            handles2, labels2 = self.axR.get_legend_handles_labels()\n",
    "            handles += handles2\n",
    "            labels += labels2\n",
    "\n",
    "        self.axL.legend(handles, labels)\n",
    "\n",
    "        if self.initial_plot:\n",
    "            self.initial_plot = False\n",
    "            # If we have saved settings, use them\n",
    "            if self.saved_settings:\n",
    "                try:\n",
    "                    # Restore axis limits\n",
    "                    self.axL.set_xlim(self.saved_settings['axLxlim'])\n",
    "                    self.axL.set_ylim(self.saved_settings['axLylim'])\n",
    "                    if self.df_axR is not None and not self.df_axR.empty and self.axR is not None:\n",
    "                        self.axR.set_xlim(self.saved_settings.get('axRxlim', self.saved_settings['axLxlim']))\n",
    "                        self.axR.set_ylim(self.saved_settings['axRylim'])\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not restore all saved settings: {e}\")\n",
    "                    self.axL.autoscale(axis='both')\n",
    "            else:\n",
    "                self.axL.autoscale(axis='both')\n",
    "            \n",
    "            try:\n",
    "                self.axLxlim = self.axL.get_xlim()\n",
    "                self.axLylim = self.axL.get_ylim()\n",
    "                if self.df_axR is not None and not self.df_axR.empty and self.axR is not None:\n",
    "                    self.axRxlim = self.axR.get_xlim()\n",
    "                    self.axRylim = self.axR.get_ylim()\n",
    "            except Exception:\n",
    "                pass\n",
    "        else:\n",
    "            try:\n",
    "                self.axL.set_xlim(self.axLxlim)\n",
    "                self.axL.set_ylim(self.axLylim)\n",
    "                if self.df_axR is not None and not self.df_axR.empty and self.axR is not None:\n",
    "                    self.axR.set_xlim(self.axRxlim)\n",
    "                    self.axR.set_ylim(self.axRylim)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Apply x-axis formatting to both axL and axR\n",
    "        self.reformatXAxis()\n",
    "        \n",
    "        # CRITICAL: Re-apply the custom coordinate formatter after formatting\n",
    "        # The reformatXAxis() may reset format_coord, so we MUST set it again\n",
    "        # Set on BOTH axes since axR (if present) is on top and handles mouse events\n",
    "        self.axL.format_coord = self._custom_format_coord\n",
    "        if self.axR is not None:\n",
    "            self.axR.format_coord = self._custom_format_coord\n",
    "        \n",
    "        # Update toolbar labels\n",
    "        if hasattr(self, 'toolbar'):\n",
    "            self.toolbar.update_xAxisLen()\n",
    "            self.toolbar.update_locator_info()\n",
    "\n",
    "        self.canvas.draw()\n",
    "\n",
    "    def apply_xaxis_formatting(self, ax):\n",
    "        # Determine the mode: either manual or automatic based on xAxisLen\n",
    "        if getattr(self, 'manual_xaxis', False) and getattr(self, 'manual_xaxis_mode', None):\n",
    "            mode = self.manual_xaxis_mode\n",
    "            is_manual = True\n",
    "        else:\n",
    "            # Automatic mode: determine mode from axis length\n",
    "            xlim = ax.get_xlim()\n",
    "            xAxisLen = xlim[1] - xlim[0]\n",
    "            is_manual = False\n",
    "            \n",
    "            if xAxisLen < 3 / 24:\n",
    "                mode = \"Minute\"\n",
    "            elif xAxisLen < 6 / 24:\n",
    "                mode = \"Hour\"\n",
    "            elif xAxisLen < 2:\n",
    "                mode = \"Day\"\n",
    "            elif xAxisLen < 14:\n",
    "                mode = \"Week\"\n",
    "            elif xAxisLen < 60:\n",
    "                mode = \"Month\"\n",
    "            elif xAxisLen < 367*1.5:\n",
    "                mode = \"Year\"\n",
    "            else:\n",
    "                mode = \"Decade\"\n",
    "        \n",
    "        # Apply locators and formatters based on mode\n",
    "        if mode == \"Minute\":\n",
    "            ax.xaxis.set_major_locator(mdates.MinuteLocator(byminute=range(60), interval=1))\n",
    "            ax.xaxis.set_minor_locator(mdates.SecondLocator(bysecond=range(60), interval=10))\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter(r'%Y-%m-%d %H:%M'))\n",
    "            ax.xaxis.set_minor_formatter(mdates.DateFormatter(r'%M:%S'))\n",
    "            self.current_locator_info = \"Major: Minute/1, Minor: Second/10\" + (\"\" if is_manual else \" (Auto)\")\n",
    "            \n",
    "        elif mode == \"Hour\":\n",
    "            ax.xaxis.set_major_locator(mdates.HourLocator(byhour=range(24), interval=1))\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter(r'%Y-%m-%d %H:%M'))\n",
    "            ax.xaxis.set_minor_formatter(mdates.DateFormatter(r'%H:%M'))\n",
    "            # Check if auto mode needs different intervals\n",
    "            if not is_manual:\n",
    "                xlim = ax.get_xlim()\n",
    "                xAxisLen = xlim[1] - xlim[0]\n",
    "                if xAxisLen < 6 / 24:\n",
    "                    ax.xaxis.set_minor_locator(mdates.MinuteLocator(byminute=range(60), interval=15))\n",
    "                    self.current_locator_info = \"Major: Hour/1, Minor: Minute/15 (Auto)\"\n",
    "                else:\n",
    "                    ax.xaxis.set_minor_locator(mdates.MinuteLocator(byminute=range(60), interval=1))\n",
    "                    self.current_locator_info = \"Major: Hour/1, Minor: Minute/1 (Auto)\"\n",
    "            else:\n",
    "                ax.xaxis.set_minor_locator(mdates.MinuteLocator(byminute=range(60), interval=1))\n",
    "                self.current_locator_info = \"Major: Hour/1, Minor: Minute/1\"\n",
    "            \n",
    "        elif mode == \"Day\":\n",
    "            ax.xaxis.set_major_locator(mdates.DayLocator(bymonthday=range(1, 32), interval=1))\n",
    "            ax.xaxis.set_minor_locator(mdates.HourLocator(byhour=range(24), interval=1))\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter(r'%Y-%m-%d'))\n",
    "            ax.xaxis.set_minor_formatter(mdates.DateFormatter(r'%H:%M'))\n",
    "            \n",
    "            # Add hourly grid lines\n",
    "            ax.grid(True, which='major', axis='x', color='grey', linestyle='-', linewidth=1)\n",
    "            ax.grid(True, which='minor', axis='x', color='lightgrey', linestyle='-', linewidth=0.5)\n",
    "            \n",
    "            self.current_locator_info = \"Major: Day/1, Minor: Hour/1, Grid: Hours\" + (\"\" if is_manual else \" (Auto)\")\n",
    "            \n",
    "        elif mode == \"Week\":\n",
    "            ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=MO, interval=1))\n",
    "            ax.xaxis.set_minor_locator(mdates.DayLocator(interval=1))\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter(r'W%U-%m-%d'))\n",
    "            ax.xaxis.set_minor_formatter(mdates.DateFormatter(r'%Y-%m-%d'))\n",
    "            \n",
    "            # Manually draw 3-hour grid lines first (lightest, independent of tick locators)\n",
    "            from datetime import datetime, timedelta\n",
    "            xlim = ax.get_xlim()\n",
    "            \n",
    "            # Convert xlim to datetime\n",
    "            start_date = mdates.num2date(xlim[0]).replace(tzinfo=None)\n",
    "            end_date = mdates.num2date(xlim[1]).replace(tzinfo=None)\n",
    "            \n",
    "            # Round start to nearest 3-hour mark\n",
    "            start_hour = (start_date.hour // 3) * 3\n",
    "            current = start_date.replace(hour=start_hour, minute=0, second=0, microsecond=0)\n",
    "            \n",
    "            # Draw vertical lines every 3 hours (very light)\n",
    "            while current <= end_date:\n",
    "                ax.axvline(x=mdates.date2num(current), color='#e8e8e8', linestyle='-', linewidth=0.3, alpha=0.7, zorder=1)\n",
    "                current += timedelta(hours=3)\n",
    "            \n",
    "            # Add major (weekly) and minor (daily) grid lines on top\n",
    "            ax.grid(True, which='major', axis='x', color='grey', linestyle='-', linewidth=1)\n",
    "            ax.grid(True, which='minor', axis='x', color='#a0a0a0', linestyle='-', linewidth=0.6, alpha=0.8)\n",
    "            \n",
    "            self.current_locator_info = \"Major: Week/1, Minor: Day/1, Grid: 3hrs+Days\" + (\"\" if is_manual else \" (Auto)\")\n",
    "            \n",
    "        elif mode == \"Month\":\n",
    "            ax.xaxis.set_major_locator(mdates.MonthLocator(bymonthday=1, interval=1))\n",
    "            ax.xaxis.set_minor_locator(mdates.WeekdayLocator(byweekday=MO, interval=1))\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter(r'%Y-%m'))\n",
    "            ax.xaxis.set_minor_formatter(mdates.DateFormatter(r'W%U-%m-%d'))\n",
    "            \n",
    "            # Enable enhanced grid for month mode (both manual and auto)\n",
    "            ax.grid(True, which='major', axis='x', color='grey', linestyle='-', linewidth=1)\n",
    "            ax.grid(True, which='minor', axis='x', color='lightgrey', linestyle='-', linewidth=0.5)\n",
    "            \n",
    "            # Add very light vertical grid lines for days\n",
    "            day_locator = mdates.DayLocator(interval=1)\n",
    "            ax.xaxis.set_minor_locator(day_locator)\n",
    "            ax.grid(True, which='minor', axis='x', color='#e0e0e0', linestyle='-', linewidth=0.3, alpha=0.7)\n",
    "            \n",
    "            self.current_locator_info = \"Major: Month/1, Minor: Day/1, Grid: Days\" + (\"\" if is_manual else \" (Auto)\")\n",
    "            \n",
    "        elif mode == \"Year\":\n",
    "            ax.xaxis.set_major_locator(mdates.YearLocator(base=1, month=1))\n",
    "            ax.xaxis.set_minor_locator(mdates.MonthLocator(bymonthday=1, interval=1))\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter(r'%Y'))\n",
    "            ax.xaxis.set_minor_formatter(mdates.DateFormatter(r'%Y-%m'))\n",
    "            self.current_locator_info = \"Major: Year/1, Minor: Month/1\" + (\"\" if is_manual else \" (Auto)\")\n",
    "            \n",
    "        elif mode == \"Decade\":\n",
    "            ax.xaxis.set_major_locator(mdates.YearLocator(base=10, month=1))\n",
    "            ax.xaxis.set_minor_locator(mdates.YearLocator(base=1, month=1))\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter(r'%Y'))\n",
    "            ax.xaxis.set_minor_formatter(mdates.DateFormatter(r'%Y'))\n",
    "            self.current_locator_info = \"Major: Year/10, Minor: Year/1 (Auto)\"\n",
    "            \n",
    "        return ax\n",
    "\n",
    "    def reformatXAxis(self):\n",
    "        self.axL = self.apply_xaxis_formatting(self.axL)\n",
    "        if self.axR:\n",
    "            self.axR = self.apply_xaxis_formatting(self.axR)\n",
    "\n",
    "    def resetXAxis(self):\n",
    "        \"\"\"Reset X-axis to show all data.\"\"\"\n",
    "        self.axL.autoscale(axis='x')\n",
    "        if self.axR:\n",
    "            self.axR.autoscale(axis='x')\n",
    "        self.reformatXAxis()\n",
    "        self.canvas.draw()\n",
    "        if hasattr(self, 'toolbar'):\n",
    "            self.toolbar.update_xAxisLen()\n",
    "            self.toolbar.update_locator_info()\n",
    "        self.save_current_settings()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys as _sys\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    def _make_and_show():\n",
    "        app = QApplication.instance() or QApplication(_sys.argv)\n",
    "        mainWin = InteractivePlotWindow(df_axL = df_flows,\n",
    "                            df_axL_Title = 'Flöde & Bräddflöde [m3/h]', \n",
    "                            df_axR = df_flowdiff, \n",
    "                            df_axR_Title = 'Flödesdiff [%]',\n",
    "                            WindowTitle='Pajala ARV Flöde',\n",
    "                            settings_file='Pajala_Flöde.json'\n",
    "                        )\n",
    "        mainWin.show()\n",
    "        # Keep references to avoid garbage collection in notebook kernels.\n",
    "        \n",
    "        # Store on the app and module globals so the objects persist after this function returns.\n",
    "        try:\n",
    "            app._pajala_mainWin = mainWin\n",
    "        except Exception:\n",
    "            pass\n",
    "        globals()['_pajala_mainWin'] = mainWin\n",
    "        globals()['_pajala_app'] = app\n",
    "        return app\n",
    "\n",
    "    # If running inside an IPython kernel (notebook), request IPython to enable the Qt event loop\n",
    "    if 'ipykernel' in _sys.modules:\n",
    "        try:\n",
    "            ip = get_ipython()\n",
    "            if ip is not None:\n",
    "                # enable GUI event loop integration; this avoids a blocking app.exec() call\n",
    "                ip.run_line_magic('gui', 'qt')\n",
    "        except Exception:\n",
    "            ip = None\n",
    "        # Create and show window but do NOT call app.exec() - the event loop is managed by IPython\n",
    "        app = _make_and_show()\n",
    "        # Keep references in the IPython user namespace if available so users can interact with them\n",
    "        if ip is not None:\n",
    "            try:\n",
    "                ip.user_ns['_pajala_app'] = app\n",
    "                ip.user_ns['_pajala_mainWin'] = globals().get('_pajala_mainWin')\n",
    "            except Exception:\n",
    "                # Fall back to module globals (already set by _make_and_show)\n",
    "                pass\n",
    "    else:\n",
    "        # Running as a script: start the blocking event loop\n",
    "        app = _make_and_show()\n",
    "        _sys.exit(app.exec())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294b2a1",
   "metadata": {},
   "source": [
    "# Velocity Chart (FT-10101)\n",
    "Interactive plot showing flow velocity in m/s with flow differences on the right axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "845f1d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned velocity DataFrame shape: (513892, 4)\n",
      "Aligned flowdiff DataFrame shape: (513892, 3)\n",
      "Warning: could not load plot settings from Pajala_Flöde.json::Hastighet FT-10101 [m/s]: [Errno 22] Invalid argument: 'Pajala_Flöde.json::Hastighet FT-10101 [m/s]'\n"
     ]
    }
   ],
   "source": [
    "# Align the velocity (with MAs) and flowdiff DataFrames to the same index\n",
    "union_idx_velocity = df_velocity_with_ma.index.union(df_flowdiff.index)\n",
    "df_velocity_aligned = df_velocity_with_ma.reindex(union_idx_velocity)\n",
    "df_flowdiff_aligned = df_flowdiff.reindex(union_idx_velocity)\n",
    "\n",
    "print(f\"Aligned velocity DataFrame shape: {df_velocity_aligned.shape}\")\n",
    "print(f\"Aligned flowdiff DataFrame shape: {df_flowdiff_aligned.shape}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys as _sys\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    def _make_and_show_velocity():\n",
    "        app = QApplication.instance() or QApplication(_sys.argv)\n",
    "        mainWin_velocity = InteractivePlotWindow(\n",
    "            df_axL = df_velocity_aligned,\n",
    "            df_axL_Title = 'Hastighet FT-10101 [m/s]', \n",
    "            df_axR = df_flowdiff_aligned, \n",
    "            df_axR_Title = 'Flödesdiff [%]',\n",
    "            WindowTitle='Pajala ARV - Hastighet FT-10101',\n",
    "            settings_file='Pajala_Flöde.json::Hastighet FT-10101 [m/s]'\n",
    "        )\n",
    "        mainWin_velocity.show()\n",
    "        # Keep references to avoid garbage collection in notebook kernels.\n",
    "        \n",
    "        # Store on the app and module globals so the objects persist after this function returns.\n",
    "        try:\n",
    "            app._pajala_velocity_mainWin = mainWin_velocity\n",
    "        except Exception:\n",
    "            pass\n",
    "        globals()['_pajala_velocity_mainWin'] = mainWin_velocity\n",
    "        globals()['_pajala_velocity_app'] = app\n",
    "        return app\n",
    "\n",
    "    # If running inside an IPython kernel (notebook), request IPython to enable the Qt event loop\n",
    "    if 'ipykernel' in _sys.modules:\n",
    "        try:\n",
    "            ip = get_ipython()\n",
    "            if ip is not None:\n",
    "                # enable GUI event loop integration; this avoids a blocking app.exec() call\n",
    "                ip.run_line_magic('gui', 'qt')\n",
    "        except Exception:\n",
    "            ip = None\n",
    "        # Create and show window but do NOT call app.exec() - the event loop is managed by IPython\n",
    "        app = _make_and_show_velocity()\n",
    "        # Keep references in the IPython user namespace if available so users can interact with them\n",
    "        if ip is not None:\n",
    "            try:\n",
    "                ip.user_ns['_pajala_velocity_app'] = app\n",
    "                ip.user_ns['_pajala_velocity_mainWin'] = globals().get('_pajala_velocity_mainWin')\n",
    "            except Exception:\n",
    "                # Fall back to module globals (already set by _make_and_show_velocity)\n",
    "                pass\n",
    "    else:\n",
    "        # Running as a script: start the blocking event loop\n",
    "        app = _make_and_show_velocity()\n",
    "        _sys.exit(app.exec())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
